{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The code below hasn't been properly tested yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "embedding = client.embeddings.create(\n",
    "    input=\"Your text goes here\", model=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "output = embedding.create(input=[\"Playing the piano\"], model='text-embedding-ada-002')['data'][0]['embedding']\n",
    "output\n",
    "\n",
    "def embed_sentence(sentence):\n",
    "    \"\"\"Embed a sentence using the OpenAI API.\"\"\"\n",
    "    embedding_output = embedding.create(input=[sentence], model='text-embedding-ada-002')['data'][0]['embedding']\n",
    "    return embedding_output\n",
    "\n",
    "\n",
    "phrase_dog = \"My dog likes food\"\n",
    "embedding_dog = embed_sentence(phrase_dog)\n",
    "phrase_cat = \"My cat hates walking\"\n",
    "embedding_cat  = embed_sentence(phrase_cat)\n",
    "phrase_I = \"I will learn about llama2\"\n",
    "embedding_I = embed_sentence(phrase_I)\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "distance_dog_cat = euclidean(embedding_dog, embedding_cat)\n",
    "distance_dog_I = euclidean(embedding_dog, embedding_I)\n",
    "distance_cat_I = euclidean(embedding_cat, embedding_I)\n",
    "\n",
    "print(f\"The distance between {phrase_dog} and {phrase_cat} is {distance_dog_cat:.2f}\")\n",
    "print(f\"The distance between {phrase_dog} and {phrase_I} is {distance_dog_I:.2f}\")\n",
    "print(f\"The distance between {phrase_cat} and 'I{phrase_I} is {distance_cat_I:.2f}\")\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "# calculate cosine distance between embedding_dog and embedding_cat\n",
    "cosine_distance_dog_cat = cosine_distances([embedding_dog], [embedding_cat])[0][0]\n",
    "\n",
    "# calculate cosine distance between embedding_dog and embedding_I\n",
    "cosine_distance_dog_I = cosine_distances([embedding_dog], [embedding_I])[0][0]\n",
    "\n",
    "# calculate cosine distance between embedding_cat and embedding_I\n",
    "cosine_distance_cat_I = cosine_distances([embedding_cat], [embedding_I])[0][0]\n",
    "\n",
    "print(f\"The distance between {phrase_dog} and {phrase_cat} is {cosine_distance_dog_cat:.2f}\")\n",
    "print(f\"The distance between {phrase_dog} and {phrase_I} is {cosine_distance_dog_I:.2f}\")\n",
    "print(f\"The distance between {phrase_cat} and 'I{phrase_I} is {cosine_distance_cat_I:.2f}\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create a list of labels for each embedding\n",
    "labels = ['embedding_dog', 'embedding_cat', 'embedding_I']\n",
    "\n",
    "# create a list of colors for each embedding\n",
    "colors = ['red', 'green', 'blue']\n",
    "\n",
    "# create a scatter plot of the embeddings\n",
    "plt.scatter([embedding_dog[0]], [embedding_dog[1]], color=colors[0], label=labels[0])\n",
    "plt.scatter([embedding_cat[0]], [embedding_cat[1]], color=colors[1], label=labels[1])\n",
    "plt.scatter([embedding_I[0]], [embedding_I[1]], color=colors[2], label=labels[2])\n",
    "\n",
    "# add a legend to the plot\n",
    "plt.legend()\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n",
    "# Ok cool! Now let's test this idea that the distance in the embedding is similar based on the semantics of a sentence!\n",
    "\n",
    "# Let's look at 3 sentences:\n",
    "\n",
    "# - My dog likes food\n",
    "\n",
    "# - My cat hates walking\n",
    "\n",
    "# - I love programming\n",
    "\n",
    "# Ok, so the expectation is that the first 2 phrases will be closer in the 'embedding space' whatever that means.\n",
    "# Why cosine distance??\n",
    "# ![](2023-11-07-16-32-24.png)\n",
    "# [source](https://platform.openai.com/docs/guides/embeddings/limitations-risks#:~:text=which%20distance%20function%20should%20i%20use%3F)\n",
    "# Yay! As we can see with both the distance equations we used (euclidean and cosine distance) we obtain outputs that align with our initial expectations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept Demo for Embeddings\n",
    "# !pip install scikit-learn\n",
    "# !pip install matplotlib\n",
    "# !pip install openai\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly_llama2",
   "language": "python",
   "name": "oreilly_llama2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
