{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What you need to know about fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. PEFT, or Parameter Efficient Fine Tuning methods.\n",
    "2. Quantization and the main target precision formats\n",
    "3. Lora & QLora\n",
    "4. SFT: Supervised Fine-Tuning\n",
    "5. RLHF: Reinforcement Learning with Human Feedback\n",
    "6. Basic system requirements\n",
    "7. Industry standard options available "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PEFT\n",
    "\n",
    "Parameter Efficient Fine-Tuning (PEFT) corresponds to methods for reducing the number of fine-tuning parameters and memory usage while achieving comparable performance to full fine-tuning for LLMs like Llama3. \n",
    "\n",
    "Notable examples: Lora & QLora.\n",
    "\n",
    "[paper](https://arxiv.org/abs/2312.12148#:~:text=Parameter%20Efficient%20Fine%2DTuning%20(PEFT,performance%20to%20full%20fine%2Dtuning.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 1 Quantization and the main target precision formats\n",
    "\n",
    "- Quantization is the process of converting a\n",
    "\n",
    "floating-point model into a fixed-point or integer\n",
    "\n",
    "representation.\n",
    "\n",
    "- The benefits include smaller model size, faster\n",
    "\n",
    "inference speed, and lower power consumption.\n",
    "\n",
    "## Intuition\n",
    "\n",
    "- Numbers are represented in computers as sequences\n",
    "\n",
    "of bits.\n",
    "\n",
    "- Integers can be unsigned or signed and have fixed\n",
    "\n",
    "bit lengths (8, 16, 32, 64).\n",
    "\n",
    "- Real numbers can be represented with fixed-point\n",
    "\n",
    "or floating-point formats. Floating-point\n",
    "\n",
    "representation includes sign bit, exponent, and\n",
    "\n",
    "mantissa components.\n",
    "\n",
    "- Quantization reduces the precision of a model by\n",
    "\n",
    "keeping only certain bits for integer values or\n",
    "\n",
    "fractional parts.\n",
    "\n",
    "- The process involves selecting appropriate\n",
    "\n",
    "quantization levels (for integers) or bit\n",
    "\n",
    "allocations (for floating-point) while ensuring\n",
    "\n",
    "minimal loss in accuracy.\n",
    "\n",
    "## Types of Quantization\n",
    "\n",
    "- There are three types of quantization:\n",
    "\n",
    "post-training quantization, quantization aware\n",
    "\n",
    "training, and dynamic quantization.\n",
    "\n",
    "- Post-training quantization applies quantization\n",
    "\n",
    "to the weights and activations of a pre-trained\n",
    "\n",
    "floating-point model without retraining.\n",
    "\n",
    "- Quantization aware training is a method that\n",
    "\n",
    "performs quantization during training while keeping\n",
    "\n",
    "accuracy in mind.\n",
    "\n",
    "- Dynamic quantization adapts the quantization\n",
    "\n",
    "levels at runtime based on the input data.\n",
    "\n",
    "\n",
    "- The paper \"Quantization and Training of Neural\n",
    "\n",
    "Networks for Efficient Integer-Arithmetic-Only\n",
    "\n",
    "Inference\" provides further information on\n",
    "\n",
    "quantization techniques.\n",
    "\n",
    "In its essence quantization represents weights and activations in lower-precision data types, such as 8-bit integers (int8), instead of the standard 32-bit floating point (float32). \n",
    "\n",
    "This process not only reduces memory usage and power consumption but also enables faster operations due to the efficiency of integer arithmetic and facilitates deployment on embedded devices which may only support integer data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA Notes\n",
    "\n",
    "[paper](https://arxiv.org/abs/2106.09685)\n",
    "\n",
    "1. **Lower-Rank Decomposition**: When we talk about lower-rank decomposition of matrices, we are essentially representing a high-dimensional matrix as a combination of two lower-dimensional matrices. In LoRA, the weight matrices of the pre-trained model are decomposed into two matrices: B and A, where B has dimensions (d x r) and A has dimensions (r x k), with 'r' being the rank of the decomposition.\n",
    "\n",
    "2. **Efficient Parameter Updates**: By decomposing the weight matrices into lower-rank components, LoRA focuses on updating and optimizing these smaller matrices during adaptation, rather than updating the entire set of parameters in the model. This approach reduces the computational complexity and memory requirements during training, making the adaptation process more efficient.\n",
    "\n",
    "3. **Capturing Important Features**: The lower-rank decomposition matrices capture the essential features of the pre-trained model that are relevant to the specific task being adapted to. This means that the model can retain its performance while using a reduced set of parameters, leading to improved efficiency without sacrificing quality.\n",
    "\n",
    "4. **Storage and Computational Efficiency**: Using lower-rank decomposition reduces the storage requirements for storing model parameters and speeds up computations during training and inference. This efficiency is crucial for scaling up large language models and deploying them in real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QLora Notes\n",
    "\n",
    "[paper](https://arxiv.org/abs/2305.14314)\n",
    "\n",
    "QLORA is a method to perform finetuning on large language models (LLMs) using low-rank adapters (LoRas) and 4-bit quantization, achieving comparable performance to full finetuning with 16-bits.\n",
    "\n",
    "- LoRAs are learnable, low-rank matrices that adapt the weight matrices of a LLM to specific tasks by adding task-specific parameters.\n",
    "- QLORA uses a two-step training process: first, pretrain LoRas on a large dataset; second, finetune the full model with the adapted LoRas.\n",
    "- The main advantages of QLORA are: reduction in computational and memory requirements, faster training times, and the ability to perform finetuning on larger models.\n",
    "- To evaluate the performance of instruction following models, MMLU (Multilingual Masked Language Understanding) is used as a benchmark for zero-shot evaluation, Vicuna for fine-tuned evaluation, and OA (Open Assistant) for chatbot evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Supervised Fine-Tuning (SFT): \n",
    "\n",
    "[llama2 paper with SFT explanation](https://arxiv.org/pdf/2307.09288)\n",
    "\n",
    "Models are trained on a dataset of instructions and responses. It adjusts the weights in the LLM to minimize the difference between the generated answers and ground-truth responses, acting as labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# RLHF\n",
    "\n",
    "[llama 2 paper with RLHF explanation](https://arxiv.org/pdf/2307.09288)\n",
    "\n",
    "Reinforcement Learning from Human Feedback (RLHF): Models learn by interacting with their environment and receiving feedback. They are trained to maximize a reward signal (using PPO), which is often derived from human evaluations of model outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic System Requirements\n",
    "\n",
    "Consumer-grade GPUs with 24GB of VRAM seems to be the small ball part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Industry Standard Options Available\n",
    "\n",
    "\n",
    "- [together ai](https://docs.together.ai/docs/fine-tuning-cli)\n",
    "- [llama 3 fine tuning with autotrain by hugging face](https://ubiai.tools/how-to-fine-tune-llama3-using-autotrain-a-step-by-step-guide/)\n",
    "- [llama3 fine tuning on alpaca dataset using unsloth](https://colab.research.google.com/drive/1mPw6P52cERr93w3CMBiJjocdTnyPiKTX#scrollTo=6bZsfBuZDeCL)\n",
    "- [special mentioning of axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)\n",
    "- [llama factory](https://github.com/hiyouga/LLaMA-Factory?tab=readme-ov-file#supported-models) github repo mention\n",
    "- replicate.ai may have some options too"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
