{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets-resources/embedding-search.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain langchain-community langchain-core langchain-ollama chromadb langchainhub pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_dir = \"./assets-resources/example_notes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(notes_dir, glob='**/*.md')\n",
    "\n",
    "doc_notes = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Define Describe Compare Classify Part Sequencing Cause Analogy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(doc_notes[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hi! How can I help you today?', response_metadata={'model': 'llama3.1', 'created_at': '2024-08-08T11:33:31.032471Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 345785542, 'load_duration': 1318709, 'prompt_eval_count': 10, 'prompt_eval_duration': 193336000, 'eval_count': 10, 'eval_duration': 149635000}, id='run-2b6a1763-70d1-4133-8bef-331394f8c90d-0', usage_metadata={'input_tokens': 10, 'output_tokens': 10, 'total_tokens': 20})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and store\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OllamaEmbeddings  # We can also try Ollama embeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=doc_notes, embedding=OllamaEmbeddings(model=\"llama3.1\"),persist_directory=\"notes-db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Notes about learning and cognition?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets-resources/example_notes/Meta learning tips and hacks.md\n",
      "assets-resources/example_notes/cognitive-load-theory.md\n",
      "assets-resources/example_notes/meta-cognitive-tools.md\n",
      "assets-resources/example_notes/Reinventing-explanation.md\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[ ] [[Meta Learning Tips]]\n",
       "\n",
       "[ ] [[16 Meta-Learning tips]]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[[Cognitive load theory]] In summary, by understanding and applying Cognitive Load Theory, you can design digital learning environments that enhance learning experiences. The key is to balance the cognitive load to ensure learners are neither overwhelmed nor under-challenged, promoting deeper understanding and sustained engagement.\n",
       "\n",
       "[[applying concepts from cognitive load theory to learning environments]]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Incorporate tools that encourage users to reflect on their learning process. This could include journals, progress trackers, and self-assessment quizzes. Encouraging meta-cognition helps users become more aware of their learning strategies and areas for improvement."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(docs[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "source Media for thought. #intelligence #learning #problemsolving [[A dynamic problem solving medium]]\n",
       "\n",
       "Miachel Nielsen in his [[Reinventing-explanation]], says:\n",
       "\n",
       "I believe it's worth taking non-traditional media seriously not just as a vehicle for popularization or education, which is how they are often viewed, but as an opportunity for explanations which can be, in important ways, deeper. Nielsen, [[Reinventing-explanation]], conclusion\n",
       "\n",
       "This agglomeration of ideas has turned maps into a powerful medium for thought. Consider the famous map of the London Underground, excerpted here:\n",
       "\n",
       "we internalize the map: the representations used in the map become the representations we use to think about the Underground. This is the sense in which this map is a medium for thought.\n",
       "\n",
       "He's created a vocabulary of operations which can be used to understand and manipulate and, most crucially of all, play with difference equations. And with enough exposure to this medium, we'd begin internalizing these operations: we'd begin to think about difference equations in this way.\n",
       "\n",
       "Nielsen's see this approach as the future of thinking about mathematics for example where mediums like these could expand how we think about mathematical objects.\n",
       "\n",
       "He now turns his attention to the design of a tool like this.\n",
       "\n",
       "In the remainder of this essay I will focus on the design of a particular type of media for thought, namely, the design of media to explain scientific ideas.\n",
       "\n",
       "Using non-traditional media to create deeper explanations of scientific ideas.\n",
       "\n",
       "In fact, we don't yet have even the basic vocabulary of digital explanation. My instinct is that such a vocabulary will be developed in the decades to come. But that is far too big a goal to attack directly. Instead, we can make progress by constructing prototypes, and learning from what they have to tell us. That's what we'll do in this essay. Nielsen \"Reinventing Explanation\"\n",
       "\n",
       "It's not about making a concept popular for the \"masses\"...\n",
       "\n",
       "(...)it's about understanding the potential of non-traditional media for serious explanations, the sort of explanations scientists use amongst themselves. So while it happens to be true that the explanations we'll discuss are accessible to a broad audience, what matters is that those explanations are, in some important ways, deeper than conventional verbal and symbolic explanations.\n",
       "\n",
       "Simpson's paradox:\n",
       "\n",
       "Some paradox where the overall probability favors one event as the local probabilities all individually favor the other event in a universe of just these two events.\n",
       "\n",
       "I could write about what it means to understand something from the perspective of these medium for thought tools.\n",
       "\n",
       "Here we are talking about optimization.\n",
       "\n",
       "To reiterate, the loss function lets us quantify the quality of any particular set of weights W. The goal of optimization is to find W that minimizes the loss function. We will now motivate and slowly develop an approach to optimizing the loss function."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(docs[3].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-llama3",
   "language": "python",
   "name": "oreilly-llama3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
