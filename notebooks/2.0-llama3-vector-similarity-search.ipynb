{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets-resources/embedding-search.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain langchain-community langchain-core langchain-ollama chromadb langchainhub pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_dir = \"./assets-resources/example_notes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cognitive-skills.md',\n",
       " 'Reinventing-explanation.md',\n",
       " 'Sketchpal.md',\n",
       " 'intro-RL-David-Silver-Lecture3.md',\n",
       " 'cognitive-load-theory.md',\n",
       " 'fundamental-logical-connectors-in-math-proofs.md',\n",
       " 'Meta learning tips and hacks.md',\n",
       " 'cerebellum-basal-ganglia.md',\n",
       " 'OMR.md',\n",
       " 'meta-cognitive-tools.md']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(notes_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader(notes_dir, glob='**/*.md')\n",
    "\n",
    "doc_notes = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "source Media for thought. #intelligence #learning #problemsolving [[A dynamic problem solving medium]]\n",
       "\n",
       "Miachel Nielsen in his [[Reinventing-explanation]], says:\n",
       "\n",
       "I believe it's worth taking non-traditional media seriously not just as a vehicle for popularization or education, which is how they are often viewed, but as an opportunity for explanations which can be, in important ways, deeper. Nielsen, [[Reinventing-explanation]], conclusion\n",
       "\n",
       "This agglomeration of ideas has turned maps into a powerful medium for thought. Consider the famous map of the London Underground, excerpted here:\n",
       "\n",
       "we internalize the map: the representations used in the map become the representations we use to think about the Underground. This is the sense in which this map is a medium for thought.\n",
       "\n",
       "He's created a vocabulary of operations which can be used to understand and manipulate and, most crucially of all, play with difference equations. And with enough exposure to this medium, we'd begin internalizing these operations: we'd begin to think about difference equations in this way.\n",
       "\n",
       "Nielsen's see this approach as the future of thinking about mathematics for example where mediums like these could expand how we think about mathematical objects.\n",
       "\n",
       "He now turns his attention to the design of a tool like this.\n",
       "\n",
       "In the remainder of this essay I will focus on the design of a particular type of media for thought, namely, the design of media to explain scientific ideas.\n",
       "\n",
       "Using non-traditional media to create deeper explanations of scientific ideas.\n",
       "\n",
       "In fact, we don't yet have even the basic vocabulary of digital explanation. My instinct is that such a vocabulary will be developed in the decades to come. But that is far too big a goal to attack directly. Instead, we can make progress by constructing prototypes, and learning from what they have to tell us. That's what we'll do in this essay. Nielsen \"Reinventing Explanation\"\n",
       "\n",
       "It's not about making a concept popular for the \"masses\"...\n",
       "\n",
       "(...)it's about understanding the potential of non-traditional media for serious explanations, the sort of explanations scientists use amongst themselves. So while it happens to be true that the explanations we'll discuss are accessible to a broad audience, what matters is that those explanations are, in some important ways, deeper than conventional verbal and symbolic explanations.\n",
       "\n",
       "Simpson's paradox:\n",
       "\n",
       "Some paradox where the overall probability favors one event as the local probabilities all individually favor the other event in a universe of just these two events.\n",
       "\n",
       "I could write about what it means to understand something from the perspective of these medium for thought tools.\n",
       "\n",
       "Here we are talking about optimization.\n",
       "\n",
       "To reiterate, the loss function lets us quantify the quality of any particular set of weights W. The goal of optimization is to find W that minimizes the loss function. We will now motivate and slowly develop an approach to optimizing the loss function."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(doc_notes[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'assets-resources/example_notes/cognitive-skills.md'}, page_content='Define Describe Compare Classify Part Sequencing Cause Analogy'),\n",
       " Document(metadata={'source': 'assets-resources/example_notes/Reinventing-explanation.md'}, page_content='source Media for thought. #intelligence #learning #problemsolving [[A dynamic problem solving medium]]\\n\\nMiachel Nielsen in his [[Reinventing-explanation]], says:\\n\\nI believe it\\'s worth taking non-traditional media seriously not just as a vehicle for popularization or education, which is how they are often viewed, but as an opportunity for explanations which can be, in important ways, deeper. Nielsen, [[Reinventing-explanation]], conclusion\\n\\nThis agglomeration of ideas has turned maps into a powerful medium for thought. Consider the famous map of the London Underground, excerpted here:\\n\\nwe internalize the map: the representations used in the map become the representations we use to think about the Underground. This is the sense in which this map is a medium for thought.\\n\\nHe\\'s created a vocabulary of operations which can be used to understand and manipulate and, most crucially of all, play with difference equations. And with enough exposure to this medium, we\\'d begin internalizing these operations: we\\'d begin to think about difference equations in this way.\\n\\nNielsen\\'s see this approach as the future of thinking about mathematics for example where mediums like these could expand how we think about mathematical objects.\\n\\nHe now turns his attention to the design of a tool like this.\\n\\nIn the remainder of this essay I will focus on the design of a particular type of media for thought, namely, the design of media to explain scientific ideas.\\n\\nUsing non-traditional media to create deeper explanations of scientific ideas.\\n\\nIn fact, we don\\'t yet have even the basic vocabulary of digital explanation. My instinct is that such a vocabulary will be developed in the decades to come. But that is far too big a goal to attack directly. Instead, we can make progress by constructing prototypes, and learning from what they have to tell us. That\\'s what we\\'ll do in this essay. Nielsen \"Reinventing Explanation\"\\n\\nIt\\'s not about making a concept popular for the \"masses\"...\\n\\n(...)it\\'s about understanding the potential of non-traditional media for serious explanations, the sort of explanations scientists use amongst themselves. So while it happens to be true that the explanations we\\'ll discuss are accessible to a broad audience, what matters is that those explanations are, in some important ways, deeper than conventional verbal and symbolic explanations.\\n\\nSimpson\\'s paradox:\\n\\nSome paradox where the overall probability favors one event as the local probabilities all individually favor the other event in a universe of just these two events.\\n\\nI could write about what it means to understand something from the perspective of these medium for thought tools.\\n\\nHere we are talking about optimization.\\n\\nTo reiterate, the loss function lets us quantify the quality of any particular set of weights W. The goal of optimization is to find W that minimizes the loss function. We will now motivate and slowly develop an approach to optimizing the loss function.'),\n",
       " Document(metadata={'source': 'assets-resources/example_notes/Sketchpal.md'}, page_content='App Name: SketchPal\\n\\nDescription: SketchPal is a drawing app designed to help users learn how to draw through interactive AI guidance. By leveraging natural language processing and AI-generated sketches, SketchPal provides a personalized and engaging learning experience for users of all skill levels.\\n\\nFeatures:\\n\\nChat Interface: Users can describe their desired drawing subject through a simple chat interface. The app interprets the text input and generates a set of AI-created sketches for the user to choose from.\\n\\nSketch Selection: After the AI generates multiple sketches, users can browse through the options and select the one they want to emulate. This allows for a more personalized drawing experience, catering to individual preferences and styles.\\n\\nGuided Drawing Canvas: Once a sketch is selected, the user is directed to a drawing canvas where they can begin to replicate the chosen sketch. The AI Sketcher provides real-time guidance and predictions for each stroke, helping users improve their drawing skills and achieve better results.\\n\\nStroke Prediction and Assistance: As users draw, the AI Sketcher predicts and suggests the next strokes to make, adjusting its guidance based on user input. This interactive feedback helps users refine their technique and progress more quickly.\\n\\nAdjustable Difficulty Levels: SketchPal offers adjustable difficulty levels, allowing users to choose a level that matches their current skill set and progress at their own pace.\\n\\nStep-by-Step Instructions: In addition to real-time guidance, SketchPal can also provide step-by-step instructions for users who prefer a more structured approach to learning.\\n\\nProgress Tracking and Sharing: Users can track their progress over time and share their drawings with friends or on social media. This feature encourages motivation and accountability, as well as allowing users to showcase their improvement.\\n\\nDiverse Drawing Subjects: SketchPal includes a wide range of drawing subjects and styles, catering to different interests and artistic goals. Users can choose from various categories, such as animals, landscapes, portraits, and more.\\n\\nTo develop SketchPal, you will need to use a combination of machine learning and AI technologies, such as natural language processing and generative models, to understand user input and create sketches. Additionally, you will need to design a user-friendly interface for chat, sketch selection, and guided drawing. Technologies like HTML, CSS, JavaScript, and relevant drawing libraries can be used to build the front-end interface, while a backend server and database will be needed to manage user data and AI-generated content.'),\n",
       " Document(metadata={'source': 'assets-resources/example_notes/intro-RL-David-Silver-Lecture3.md'}, page_content='raw\\n\\nIntroduces [[Dynamic Programming]]\\n\\n[[Dynamic Programming]] assumes full knowledge of the MDP. It is used for planning in MDP. (in RL you have two big problems: the [[Exploration & Exploitation in RL]] and the [[Prediction and Control in RL]])\\n\\n[[Policy Evaluation]]\\n\\n[[Policy Iteration]]\\n\\nExample: \"Jack Rental\\'s\"\\n\\n![[Pasted image 20210301150828.png | 400]]\\n\\n![[Pasted image 20210301150925.png | 400]]\\n\\nIn this example, we see how we can use the value function which here is how much you get from having x amount of cars in the first location and x\\' amount on the other, and use it to calculate a better policy by acting greedily (improving on v):\\n\\n![[Pasted image 20210301151110.png | 500]]\\n\\n![[Pasted image 20210301153007.png]]\\n\\n![[Pasted image 20210301153858.png]] So the next policy $\\\\pi\\'$ is chosen as the action that maximizes $q_{\\\\pi}(s,a)$\\n\\nIf you improve on the first step and then follow the regular policy, it\\'s better than always following the regular policy, because you are going to get at least as much reward as before.\\n\\nAnd now we iterate: ![[Pasted image 20210301153825.png]]\\n\\nHere we are unrolling the greedy for all steps and showing that taking this greedy policy is better for all steps, it will yield at least as much reward as the previous policy so it\\'s better.\\n\\nIt is not guaranteed to keep getting better and find the optimal value!\\n\\nIf improvements stop, this can be described as saying: ![[Pasted image 20210301154241.png]]\\n\\nHere we have the Bellman optimality equation satisfied:\\n\\n![[Pasted image 20210301154326.png]] This is the one step look ahead of the [[Bellman optimality equation]]. If this equation is satisfied then that means: $$v_{\\\\pi}(s) = v_*(s) \\\\text{ }\\\\forall s \\\\in S$$ He states in minute 54:20. that is it stops improving when we are following this greedy approach, that means that the Bellman optimality equation is satisfied and we found our optimal policy. It solves the MDP because it satisfied the Bellman optimality Equation.\\n\\nThink of policy improvement as [[partial ordering]] of policies.\\n\\nSo we don\\'t want to evaluate policies when we are already in the optimal policy, however in the current version of the loop for policy evaluation, we have to. Can we truncate this process to reach the best policy faster and stop?\\n\\nModified Policy Iteration\\n\\nBasic idea: stop early.\\n\\nOne thing is to have a stopping condition: ![[Pasted image 20210301160111.png]]\\n\\nOr simply stop after k iteration of iterative policy evaluation?\\n\\n[[Principle of Optimality]]\\n\\nSo the optimal policy corresponds to an optimal first action $A_*$ followed by an optimal policy for how to act from state $S\\'$ onwards...\\n\\n[[Value Iteration]]\\n\\nSummary: ![[Pasted image 20210301164804.png]] This final table is basically, given the problem of planning divided into its 2 subproblems: Prediction and Control, we have so far 1 approach to solve Prediction and 2 to solve Control, we use: - Iterative policy evaluation with the bellman expectation equation to get the best possible prediction (solves Prediction) - Policy Iteration with bellman expectation equation + greedy policy improvement (solves Control) - Value Iteration with [[Bellman optimality equation]] (solves Control)\\n\\nBoth prediction and control aim to find best policy...no? Evaluating the future and optimizing the future are interchangeable goals no?Should elucidate the difference in the lecture\\n\\nAssynchronous Dynamic Programming\\n\\nNot using all states to perform the computations ![[Pasted image 20210301165757.png]]\\n\\nThree ideas for asynchronous dynamic programming\\n\\nIn-place dynamic programming\\n\\n![[Pasted image 20210301165954.png]]\\n\\nValue function is updated immediately.\\n\\nWe plug in the latest information on the $v(s\\')$. How do you order states to compute things in the most efficient way?\\n\\nPrioritized sweeping\\n\\nHere you wanna come up with some measure of how important it is to update any state in your MDP, so you keep a priority queue that tells us which states are better than others. ![[Pasted image 20210301170221.png]] We use the magnitude of the difference between the value of a state now compared to before as a guide to tell us which states to update\\n\\nReal-time dynamic programming\\n\\nSelect the states that the agent actually visits. Update around these real samples that the agent actually visited. Real experience as a guide ![[Pasted image 20210301170727.png]]\\n\\nFull-Width Backups\\n\\nUsing full-width backups is expensive! ![[Pasted image 20210301170835.png]] Sometimes you can\\'t do one backup because there are too many states, so you sample. ![[Pasted image 20210301170956.png]]\\n\\n![[Pasted image 20210301171015.png]]\\n\\nGridworld Appendix\\n\\n![[Pasted image 20210402170211.png]]\\n\\n![[Pasted image 20210402170217.png]]\\n\\n![[Pasted image 20210402170231.png]]\\n\\nContraction Mapping\\n\\n![[Pasted image 20210301171043.png]]\\n\\nNext\\n\\n[[intro_RL_David_Silver_Lecture4]]\\n\\nReferences\\n\\nhttps://www.youtube.com/watch?v=Nd1-UUMVfz4'),\n",
       " Document(metadata={'source': 'assets-resources/example_notes/cognitive-load-theory.md'}, page_content='[[Cognitive load theory]] In summary, by understanding and applying Cognitive Load Theory, you can design digital learning environments that enhance learning experiences. The key is to balance the cognitive load to ensure learners are neither overwhelmed nor under-challenged, promoting deeper understanding and sustained engagement.\\n\\n[[applying concepts from cognitive load theory to learning environments]]'),\n",
       " Document(metadata={'source': 'assets-resources/example_notes/fundamental-logical-connectors-in-math-proofs.md'}, page_content='raw\\n\\nAND\\n\\nOR\\n\\nNot\\n\\nImplies\\n\\nFor all\\n\\nthere exists\\n\\nReferences\\n\\nhttps://www.coursera.org/learn/mathematical-thinking/lecture/QeAe0/lecture-1-introductory-material'),\n",
       " Document(metadata={'source': 'assets-resources/example_notes/Meta learning tips and hacks.md'}, page_content='[ ] [[Meta Learning Tips]]\\n\\n[ ] [[16 Meta-Learning tips]]'),\n",
       " Document(metadata={'source': 'assets-resources/example_notes/cerebellum-basal-ganglia.md'}, page_content='are involved in procedural memory, such as learning to ride a bike.'),\n",
       " Document(metadata={'source': 'assets-resources/example_notes/OMR.md'}, page_content='raw\\n\\nIn this assay, fish are placed in a circular tank with an opaque column in the center. Black and white stripes rotate around the tank and the fish is tasked with swimming in the direction of the stripe motion. Like the escape response, the OMR focuses on the visuomotor capabilities of the adult zebrafish.\\n\\nIn the vae paper they recorded from M1 (motor cortex) and PMd (dorsal premotor cortex)\\n\\nReferences'),\n",
       " Document(metadata={'source': 'assets-resources/example_notes/meta-cognitive-tools.md'}, page_content='Incorporate tools that encourage users to reflect on their learning process. This could include journals, progress trackers, and self-assessment quizzes. Encouraging meta-cognition helps users become more aware of their learning strategies and areas for improvement.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\", temperature=0)# temperature closer to 1 yields a more creative answer and temperature closer to 0 yields a more precise answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Oh boy, are you going to love this!\\n\\nImagine you have a super smart friend who knows EVERYTHING about the world. They can tell you what your favorite cartoon character\\'s name is, or how to make a peanut butter and jelly sandwich.\\n\\nBut instead of being a real person, this \"friend\" is actually a computer program that can understand and talk like a human. It\\'s called a Large Language Model (LLM).\\n\\nThe LLM is like a giant library in your brain, but instead of books, it has all the words and ideas from the internet! When you ask it something, it looks through this huge collection to find the answer.\\n\\nHere\\'s how it works:\\n\\n1. You ask the LLM a question or give it a task.\\n2. The computer program uses special math tricks (called \"algorithms\") to search through its giant library of words and ideas.\\n3. It finds the best answer or solution, and then... TA-DA! It tells you what it found!\\n\\nLarge Language Models are like super-smart computers that can understand and respond to human language. They\\'re not perfect yet, but they\\'re getting better every day!\\n\\nDoes that make sense?', response_metadata={'model': 'llama3.1', 'created_at': '2024-08-08T17:53:17.85226Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 4950302084, 'load_duration': 800625125, 'prompt_eval_count': 23, 'prompt_eval_duration': 87605000, 'eval_count': 240, 'eval_duration': 4059833000}, id='run-4082e059-92d3-4ccf-9051-c7f76d310b0d-0', usage_metadata={'input_tokens': 23, 'output_tokens': 240, 'total_tokens': 263})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi, explain large language models to a 5 year old.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and store\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OllamaEmbeddings  # We can also try Ollama embeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=doc_notes, embedding=OllamaEmbeddings(model=\"nomic-embed-text\"),persist_directory=\"notes-db-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Notes about learning and cognition?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets-resources/example_notes/meta-cognitive-tools.md\n",
      "assets-resources/example_notes/cerebellum-basal-ganglia.md\n",
      "assets-resources/example_notes/cognitive-load-theory.md\n",
      "assets-resources/example_notes/Meta learning tips and hacks.md\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Incorporate tools that encourage users to reflect on their learning process. This could include journals, progress trackers, and self-assessment quizzes. Encouraging meta-cognition helps users become more aware of their learning strategies and areas for improvement."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "are involved in procedural memory, such as learning to ride a bike."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[[Cognitive load theory]] In summary, by understanding and applying Cognitive Load Theory, you can design digital learning environments that enhance learning experiences. The key is to balance the cognitive load to ensure learners are neither overwhelmed nor under-challenged, promoting deeper understanding and sustained engagement.\n",
       "\n",
       "[[applying concepts from cognitive load theory to learning environments]]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(docs[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[ ] [[Meta Learning Tips]]\n",
       "\n",
       "[ ] [[16 Meta-Learning tips]]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(docs[3].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-llama3",
   "language": "python",
   "name": "oreilly-llama3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
