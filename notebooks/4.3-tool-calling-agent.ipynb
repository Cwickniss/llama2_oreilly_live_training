{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29317d99-1605-410d-b838-fbc3469e4856",
   "metadata": {},
   "source": [
    "# Local Tool Calling Agent\n",
    "\n",
    "Here, we'll build a [tool calling agent](https://python.langchain.com/v0.1/docs/modules/agents/agent_types/tool_calling/) using local models.\n",
    "\n",
    "We'll use the [new fine-tune from Groq](https://wow.groq.com/introducing-llama-3-groq-tool-use-models/) with tool calling via Ollama:\n",
    "\n",
    "Access the model:\n",
    "\n",
    "```\n",
    "ollama pull llama3-groq-tool-use\n",
    "ollama pull llama3.1\n",
    "```\n",
    "\n",
    "And also, we'll use the Ollama partner package.\n",
    "\n",
    "This notebook accompanies the video here:\n",
    "\n",
    "https://www.youtube.com/watch?v=Nfk99Fz8H9k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "666175b4-f056-489d-9d94-a0a666270794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-xxx\"\n",
    "\n",
    "# os.environ[\"TAVILY_API_KEY\"] = \"tvly-xxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "120c1da8-e45e-4ffa-9ac1-a536026c7e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.5.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.14.0-cp311-cp311-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.5.1-cp311-cp311-macosx_12_0_arm64.whl (11.0 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.14.0-cp311-cp311-macosx_14_0_arm64.whl (23.1 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.1 scipy-1.14.0 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-ollama langchain-openai langgraph\n",
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c0504b-007a-4af6-9976-c7294ed26b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /// LLM ///\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    # model=\"llama3-groq-tool-use\",\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7e4451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Tom Cruise is a highly acclaimed American actor known for his versatility and dedication to his craft. Here\\'s a brief rundown on his life and career:\\n\\n**Early Life**\\n\\nThomas Cruise Mapother IV was born on July 3, 1962, in Syracuse, New York. He grew up in a Catholic family with three siblings. His parents divorced when he was 11 years old, and he was raised by his mother, Mary Lee Pfeiffer, and her second husband.\\n\\n**Career**\\n\\nCruise began his acting career at the age of 18, landing small roles on television shows like \"The Last Resort\" and \"Emerald Point N.A.S.\" He made his film debut in 1981 with a minor role in the movie \"Endless Love.\"\\n\\nHowever, it was his breakout performance in the 1983 film \"The Outsiders\" that caught the attention of Hollywood. This led to more significant roles in films like \"Top Gun\" (1986), which catapulted him to stardom.\\n\\nThroughout the 1990s and 2000s, Cruise established himself as a leading man with starring roles in movies such as:\\n\\n* \"A Few Good Men\" (1992)\\n* \"The Firm\" (1993)\\n* \"Interview with the Vampire\" (1994)\\n* \"Jerry Maguire\" (1996)\\n* \"Mission: Impossible\" (1996) - a franchise that has become one of his most successful and enduring projects\\n\\n**Personal Life**\\n\\nTom Cruise is known for his strong faith in Scientology, which he joined in 1990. He has been married three times:\\n\\n1. Mimi Rogers (married 1987-1990)\\n2. Nicole Kidman (married 1990-2001)\\n3. Katie Holmes (married 2006-2012)\\n\\nCruise is also known for his high-profile relationships and controversies, including a highly publicized divorce from Katie Holmes in 2012.\\n\\n**Awards and Recognition**\\n\\nThroughout his career, Tom Cruise has received numerous awards and nominations, including:\\n\\n* Three Golden Globe Awards\\n* Three Academy Award nominations\\n* A star on the Hollywood Walk of Fame\\n\\n**Philanthropy**\\n\\nCruise is involved with several charitable organizations, including the Starkey Hearing Foundation, which provides hearing aids to those in need.\\n\\nOverall, Tom Cruise has had a remarkable career spanning over four decades, with a wide range of film roles and a dedicated fan base.', response_metadata={'model': 'llama3.1', 'created_at': '2024-08-08T20:25:18.892873Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 8801348459, 'load_duration': 23487625, 'prompt_eval_count': 17, 'prompt_eval_duration': 217229000, 'eval_count': 497, 'eval_duration': 8559529000}, id='run-40a4fbc8-bc9d-4066-902a-125e95576390-0', usage_metadata={'input_tokens': 17, 'output_tokens': 497, 'total_tokens': 514})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hi, tell me about Tom Cruise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7fd03f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', response_metadata={'model': 'llama3.1', 'created_at': '2024-08-08T20:26:03.63928Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'retrieve_guest_number', 'arguments': {'guest_name': 'Bob'}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 714758375, 'load_duration': 23445083, 'prompt_eval_count': 162, 'prompt_eval_duration': 385313000, 'eval_count': 19, 'eval_duration': 304755000}, id='run-dcd194a1-6f6c-48b3-b4d2-c7021a34802b-0', tool_calls=[{'name': 'retrieve_guest_number', 'args': {'guest_name': 'Bob'}, 'id': 'bbe6a4e4-2ac3-4e36-9a4c-9037ab567b01', 'type': 'tool_call'}], usage_metadata={'input_tokens': 162, 'output_tokens': 19, 'total_tokens': 181})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_guest_number(guest_name: str) -> int:\n",
    "    \"\"\"Given a guest name this function returns the guest number.\"\"\"\n",
    "    return [\"Alice\", \"Bob\", \"Charlie\", \"David\"].index(guest_name) + 1\n",
    "\n",
    "\n",
    "tools = [retrieve_guest_number]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "llm_with_tools.invoke(\"Use your tools to figure out the guest number of Bob.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14d83702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# /// Retriever tool ///\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# List of URLs to load documents from\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "# Load documents from the URLs\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# Initialize a text splitter with specified chunk size and overlap\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "\n",
    "# Split the documents into chunks\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add the document chunks to the \"vector store\" using OpenAIEmbeddings\n",
    "vectorstore = SKLearnVectorStore.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever(k=4)\n",
    "\n",
    "\n",
    "# Define a tool, which we will connect to our agent\n",
    "def retrieve_documents(query: str) -> list:\n",
    "    \"\"\"Retrieve documents from the vector store based on the query.\"\"\"\n",
    "    return retriever.invoke(query)\n",
    "\n",
    "\n",
    "# /// Search Tool\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "web_search_tool = TavilySearchResults()\n",
    "\n",
    "\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Run web search on the question.\"\"\"\n",
    "    web_results = web_search_tool.invoke({\"query\": query})\n",
    "    return [\n",
    "        Document(page_content=d[\"content\"], metadata={\"url\": d[\"url\"]})\n",
    "        for d in web_results\n",
    "    ]\n",
    "\n",
    "# Tool list\n",
    "tools = [retrieve_documents, web_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aecdb3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3.1\", temperature=0)\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "189e71a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', response_metadata={'model': 'llama3.1', 'created_at': '2024-08-08T20:28:25.044522Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'web_search', 'arguments': {'query': 'funniest jokes about cat people'}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 732691292, 'load_duration': 24863417, 'prompt_eval_count': 207, 'prompt_eval_duration': 350643000, 'eval_count': 22, 'eval_duration': 355892000}, id='run-f8d00e9d-011a-4f87-88a7-758c08add56c-0', tool_calls=[{'name': 'web_search', 'args': {'query': 'funniest jokes about cat people'}, 'id': '45ac2d54-5f66-4a0f-8df7-5e62215b926a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 207, 'output_tokens': 22, 'total_tokens': 229})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"Use your search tool to search the web for the funniest jokes about cat people.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30052f47-2b5d-46f5-9873-eb716145cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        \"\"\"\n",
    "        Initialize the Assistant with a runnable object.\n",
    "\n",
    "        Args:\n",
    "            runnable (Runnable): The runnable instance to invoke.\n",
    "        \"\"\"\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        \"\"\"\n",
    "        Call method to invoke the LLM and handle its responses.\n",
    "        Re-prompt the assistant if the response is not a tool call or meaningful text.\n",
    "\n",
    "        Args:\n",
    "            state (State): The current state containing messages.\n",
    "            config (RunnableConfig): The configuration for the runnable.\n",
    "\n",
    "        Returns:\n",
    "            dict: The final state containing the updated messages.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)  # Invoke the LLM\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n",
    "# Create the primary assistant prompt template\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant tasked with answering user questions. \"\n",
    "            \"You have access to two tools: retrieve_documents and web_search. \"\n",
    "            \"For any user questions about LLM agents, use the retrieve_documents tool to get information for a vectorstore. \"\n",
    "            \"For any other questions, such as questions about current events, use the web_search tool to get information from the web. \",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Prompt our LLM and bind tools\n",
    "assistant_runnable = primary_assistant_prompt | llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40504a0b-8a99-4420-a6bf-561c62e893d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCADbAMcDASIAAhEBAxEB/8QAHQABAAICAwEBAAAAAAAAAAAAAAUGBwgBAwQJAv/EAFcQAAEDBAADAgcIDAkJCQEAAAECAwQABQYRBxIhEzEIFBYiQVGUFRcjVVZh0dMyNkJUcXSBkZOVtNIJNThSU3WSstQkM2JjcnOhs8EYNEVXgoOEscPx/8QAGgEBAQADAQEAAAAAAAAAAAAAAAECAwQFB//EADURAQABAwAFCgMIAwAAAAAAAAABAgMRBBIhMVETFEFSYXGRobHBFSPRBSIyM1OB4fBCQ8L/2gAMAwEAAhEDEQA/APqnSlKBSlKBSvJdLnHs1vfmylFLDKeY8qSpSj3BKUjqpROgEjqSQB1NQfk9Lyb4e/OOsxVbLdnjulCEJ9HbKSduL9YB5BvQCtc6ttNETGtVOI/u5cJmTfbbCcKJFwisLHQpdfSkj8hNdPlVZfjiB7Sj6a6o+F4/EbCGLFbWkAAaREbHd0Hort8lbL8TwPZkfRWfye3yNh5VWX44ge0o+mnlVZfjiB7Sj6aeStl+J4HsyPop5K2X4ngezI+inye3yXYeVVl+OIHtKPpp5VWX44ge0o+mnkrZfieB7Mj6KeStl+J4HsyPop8nt8jYeVVl+OIHtKPprlGTWdxQSi7QVKPoTJQT/wDdceStl+J4HsyPorheJ2NxBSqzW9ST0IMVBB/4U+T2+RsSiVBaQpJCkkbBB2CK5qsLwKDBWp+wKVjssnm/yIajrP8ArGPsFA+kgBXfpQJ3UjY7y5PW/DmMeKXOLoPMg7QsHucbPpQrR0e8EEHqKxqojGtROY8JTHBLUpStKFKUoFKUoFKUoFKUoFKUoFKUoKvdtXbOLTbl6VGgsLuTiD907zBtn8IG3VdfSEHvGxaKrDo8T4ksOL2ET7WppCtdOZl3m1v1kPEj/ZPqqz10Xd1ERux9c+ayUpSudFAhceMHuWUXLHYd4cmXa3KfRIajQJLiA4ykqdbS6lsoW4kA7QlRVsa1vpVZ4U+E9jfEPhnMzC4NS7AxAK1TUPwJXZtI7dxprkcUykPKIQNhvmKSrRAPSqjhwvGOeEAYOF2TLbZityudwkZNBvluKLU25yqUmZCkK9LroSezQpQIWSUoIquYvc86w7wd7hhFnx3J7VllinuplzI1rUrtITlzUp12A4oFt93xdwqSkbOwemwKDOVq8ILAbziGQZPFv27Rj6Su6qdhyGn4aeXm2thbYdGx1HmddHW9VVM78LHFMYtNjuNrbn3yHcb3GtSpLNrm9kG3DtbzSgwQ/pPVIbJ5yfNJ1qsG3bDbxLsvH1NmxvO5MPIcQiItb2RsSpEue8yZCXEjtOZxKtup5WlBKtbKU8vWs7cfrDcU8PcHm2myzLonGshtN1k262sFyT4swsBwNNDqtSQd8o69DQZfs92j320w7lE7bxWWyl9rxhhbDnKobHM24ErQdHqlQBHcQK9lRuOXxvJbJEubUSbAbkp50x7lGXGkIGyNLbWApJ6b0R6RUlQKrGXatdzsN5RpK25iIDx6+ezIUGwn9KWVfkPrqz1WM8T43Fs9vSCXZd1iFIA30ZdEhRPqHKyrr84rosfmRE7unu6fJY3rPSlK50KUpQKUpQKUpQKUpQKUpQKUpQRWRWZV4iNFhxLFwiOiTDfWCQ26AR1AIJSpKlIUAeqVqAI7667XfI18D9vlNCNcUJKZNueOzy9xUnYHO2d9FgaPcdEFImajrzj1uyFptu4RG5PZEqacO0uNKI0VIWNKQddNpINbqaqZjVr3en9/vbe9SB4NnCdJBHDfFgR3EWhj92uP+zXwn/8ALbFf1Qx+7VhODFvpHyK+x0dAEeOB3Q/C4lSj+U7p5EyPlVfv0zP1VZalvr+UmI4rJHjtRI7TDLaWmWkhCG0DSUpA0AB6ABXZVX8iZHyqv36Zn6qnkTI+VV+/TM/VU5O31/KTEcVopWvvgtXrIeMfBe05VfsouqLnKky2nBDU023ytSXG06BbJ+xQN9e+steRMj5VX79Mz9VTk7fX8pMRxeDIuB3DzLrzIu17wiwXe6SeXtpk23NOuucqQlPMpSSTpKQPwAVHq8G/hStKArhxi6ggcqQbSweUbJ0PN9ZJ/LU/5EyPlVfv0zP1VBhLxBCsnvy0nprt2h/xDYNOTt9fykxHF3Wy04vwtx0RbdCt2NWZtZUmPEaSw12ij3JQkDalH0AbJ7tmubPCkXW7C+z2DGKWlMwYq/s2m1EFS1j0LVyp6fcgAd5VXZa8LtVqmiaGnZlwAIEyc+uQ6nfeEqWTyA+pOh81TtSaqaImLfT0/Q2RuKUpWhClKUClKUClKUClKUClKUClKUClKUClKUClKUGu/gB/yYce/Hbj+2vVsRWu/gB/yYce/Hbj+2vVsRQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQKUpQa7+AH/Jhx78duP7a9WxFa7+AH/Jhx78duP7a9WxFApSlApSlApSlApSlApSlApSlApSlApSlApSlApSq3e8oksXFdttENqbNaQlchyQ8WmWAr7EEhKipZAJ5QOgAJKeZO9lFuq5OKV3rJSqR7u5h94WP2t76unu7mH3hY/a3vq66Oa18Y8YMLvWjf8J/wLVlOE2ziTbI5cuNgAh3HkGyqEtZKFf8AtuKPd6HVE9E1tb7u5h94WP2t76uo/IU5FlVhuNlulnsMu23CO5Ekx1y3tONLSUqSfg/SCac1r4x4wYfMf+Dy4KOcU+O8K9yW1CyYkpu6vuDYCpIVuM3sdx508/qIaUPTX1/rXXwdODF08HDBXccszFpuCpEtyZJnyJDiXHlK0EggN6ASgJTodN7PTmNZT93cw+8LH7W99XTmtfGPGDC70qke7uYfeFj9re+rp7u5h94WP2t76unNa+MeMGF3pVLRmF4tI7e+W6Ei3D/OyYElbimB/PUhSBtA6bIOx360CaulaLlqq3+IxgpSlakKUpQKUpQKUpQKUpQKUpQKUpQKoVoPNleZ79FyaA6ejxGMf+pq+1QbP9teaf1m1+wxa7tF/wBnd/1DKN0pulYE4/Z1kdsyI2vDcjvLN5h2pVwetFmskWYlKeZYQ7JekKSENqKSkIQQs8qiN1W8j4wZnPs/D3KZN7fwbCbxjkefNvVutDdwZYuLvIezkhYUpqPyq6LGupPMsVlNUQxbP15LfeIF3MoQZsaaYj6o0gR3Uudi8kAqbXonlUNjaT1GxWEPLrKIPHpy25JksjHMdmS2mseiItTTtuvDSmQSgzNFSJBXz6QVJ2EjlCt1SIWT8QrRh2R+5NxlSEQM9mwr1e7RY4jtxRCQ0nTwjIaSh1fPyBauRS+XuB10aw2vU4hCkJUpKVLOkgnqTrfSv1WrmQtXDPeKXAy42XiRLktTbRdi1ebdAiJDpQlkrcDbjSwlSwQhSSPN7PoEnm3xxv40ZVh+QZLeMUv11u9sxqRGbuFrYscU2uOT2XaMPS1rS8pwpXzfA75OdIUO801htJX5LiA4lBUkLUCQknqQNbOvyj89a/ZZkue3jOOLUOzZibBBxK3xJsGO3bY7/auuRVuFDi3Ek9mS31A0rzuigBqoK1u3viRx44ZZGxks2wLuuAG6uRoceM4hIU9DW4yO1bWeVZWNnfMOQcpGztrDYbNQDht+BAI8QkdCNg/Bqq5WklVqhEkkllBJP+yKp2a/abfvxB//AJaquFn/AIphf7hH90Vb/wCTT3z6QvQ9lKUrzkKUpQKUpQKUpQKUpQKUpQKUpQKoNn+2vNP6za/YYtX6qPdYsrG8guM9MKROt9zWh5a4bRccYdS2hohSAOYpKUJIUN6IIIHTfbosxmqnpmPeJ9mUdKo5jwStWYZS9fjeL5ZZMyEi3XFm0TAw3cI6VKKUO+aVDXaLAU2pCtKI3UFP8Ge0T8QteLeVmWR8ehW4Wly3R7g2hqZFCiQ28Oy/mq5OZHKopABJ76u134lWewWyVcrozdrdb4rZdfly7TKaaaQO9SlqbASB6ya67FxSseUWmNdbMi6XW2SU87EyFapLzLo2RtK0tkEbBHQ+iurkK+rJqzwQU7gLabpllvvEy+5BKgW+axcImPuzUm3MSGUBLS0I5OcBOgQnn5ebqQTXL/A2GiFc2bXlOS4+7cL2/fnpNrmNNuds6kJW3otKSprQ2EqSog9d7A1a/LON8WX79SS/qqeWcYf+GX79SS/qqchX1ZNWeCkveDjjjeN4larVcr3YHsXU+q3XS2y0iWC/vxjnUtC0r7QqKlbT392q8WTeC/juVIyGNJv2SxrTf1iRcbVEnpbjvyeRKPGTpvm5/g0KI5uQqSCUHuq5Y/xXx/LLW3c7Gbjeba6VJRMt9skvsrKVFKgFobIJCgQevQgipHyzjfFl+/Ukv6qpyFfVNWeCJi8KLZHuGYTlzrhIlZTDjwp7jq2+iWmVMpUgBAAUUrJO9jfcAOlQk7wf7M/Bw1uBfL9Yp2K20WmFc7ZJbbkOxeRtBbe5m1IUD2SFHSRojY1Vx8s43xZfv1JL+qqGyfjPi2FR4z+QyZtiYkuhhl25W6RHS64e5CStABUfUOtXkK+rJqzwT+a/abfvxB//AJaquFn/AIphf7hH90VRJ8qTmFvk2m3224sGa0phyXOhLjNx0KBSpfwqQVEDekgHZI3pO1DIjLKY7LbSBpCEhKR6gOgrRpH3bdNE78z7E7IfulKV57EpSlApSlApSlApSlApSlApSvytaW0KUpQSlI2VE6AFB+qpXFjilD4SY5Husq0Xi+uSpjUCNAskNUmQ685vlGh0A6HqSPQBskA+e6cQr0c9xK02DFXr/jN3jOTJmUsS2xEiNBPwYT1JcUtRQRrXmnaebSuXv4VcK4XCe0XKFFu94vjtxnu3GTNvUxUl5bi9DQJ6ABKUjoOutnZoOiBgN7f4i5JfLzlT94xW5wUQYmJPRGxFjp0O1U5sbcUo8w6681ZB5tJ1eWGG4zLbLLaWmm0hCG0JCUpSBoAAdwFdlKBWuPh4cc/eW4Gz2oEjscjyLmtlv5TpbaVD4Z4ekcqDoEdyloNbHVgbwg/A4xDwk8ktt5ye+ZJDct8TxRiJa5TDbCRzqWpfK4ys86uYAkEbCE9OlBqb/Bd8dfcfI7pwvukgJiXTmuNqLivsZKUjtWh/ttpCgO4dkr0qr6V18+vAn8DDDMnxDDeKki8ZFHyKDdnZLceNKYTFUY0taUJUkslZSoNgKHON7VrW6+gtArplQ2JzXZSWG5DfMlfI6gKHMkhSTo+kEAg+ggV3UoMdysRv+IZNmWZWu93nJxOt/NFwyS+0mKmW2gBPYOKA7ILCUpI3ralKPMdamcIzsZPjdhm3i2P4jebq2tSbDd3EJlpWgnnSEg+eBrm2OvKUkhO9C11Vcy4W4rxAuuP3PILLHuVxsEtM22SnNhyM6Ck7SQRsEpSSk7B5RsdBQWqlYqdy3KuFTHEHI+Ic+33DCoLqZlods8J0zWY6iQpp5sbCuTzNKG97UokDonIeN5Fbsux+3Xu0SPG7XcY6JUWQEKR2jS0hSVaUARsEHqBQSVKUoFKUoFKUoFKUoFKUoIjKsusuD2R28ZBc41ntbS223JktwIbQpa0oRtR6DalJG/nqmXDH8k4k3POcXzOyW2Pw6lxkQoC4c53x6ZzJ26tZTyhtPUJCehBQfskkGrHxOsdoyLAL7Cv1lTkdq8WU+9alDfjXZfCpQOo6lSE6+fVccMMyb4g8PbBkbVtkWdu4xEPiBLSQ7H2NFCtgdxGt6699BK4zjNrw3H7fY7JCat1pgMpYjRWRpLaB3Aek/hPUnqak6UoFKUoFdMuWxAivSpTzcaMwhTjrzywlDaANlSiegAAJJNR+VZXZ8Hx6dfb9cWLVaILZdkS5KuVCE/8AUk6AA6kkAAk1rExByfw3Z7cq5Nz8R4EsuBbEAkszsnIOwtzXVuNsAgDqrvGzooC0+AAoL8F7HFpIUlUy4lKgdgjx17qK2KrxWWyW/G7TEtdqhMW62xG0sx4sZsIbaQBoJSkdAK9tApSlApSlBwRsaPUVTL5w1N1z7GcniZHeLQmzNOR3LRDkagzWVJOkutEa2lXKQoddJ16iLpSgpPDvNr9kaLs1lWKuYdNi3F2JFQ/MafbnMjzm3WlJOztJTsEdDsddEC7Vini/Fwl/P+Fq8omTY16avDirA3FBLb0nsjzJd0k6Ty+sjr6aytQKUpQKUpQKUpQKUr8rcQ2NrUEj/SOqDEnhDeEvj3g1Wyz3HJbLf7lAubrjCJNmitutsuJCVBDqnHEBKlgqKQNkhtf82tK4X8JznlymLsOPY5bbtdJ19W3bLheUlO4biylhhcdlSdOjaNrDqh3jR6Kr6D8SMExzivhd0xbI2WptquDRbcSVDmbV9y4gn7FaTog+givmhwj8FC88MfDixTGL0343ZYMpd6h3ZKfgpMdhKnGl9/RXaJbSpJO0k+kEE3Ej6s0rq8aZ/pm/7Qp40z/TN/2hTEjtqn8VeLGM8GMOl5LlVxTAt7HmoQPOdkOEea00jvWs67vwkkAEiC448fce4GY0xOuCXbteLg54taLFbxzyrjI6ANtpG9Dak7VrpsdCSlJxzwq4CZFnuYROKXGtTM/JmvPsmLNnmgWBBOx5vULf7tqO9EA7JCSmCJxXhdlPhS5DBzji3AcsuDxHBIx/h84o/CfzZM8fdKIPRs929EAcwXtO22hltDbaEobQAlKUjQAHcAK/VKBSlKBSlKBSlfhbqG9c60p33cx1QfuvJdn5cW1TXrfFROntsrXHiuvdil5wJJSgr5VcgJ0ObR1vej3V3eNM/wBM3/aFPGmf6Zv+0KuJHzoyD+FJQ5eIouXBeL4/apCykTrwFvRnRtKuQmKC2vvBPf6K298F3j3J8I7hs9lz+MLxVr3QdhsR1zPGg+hCEEupX2bfTmUtGtHq2evoGjfh0eC3Pe8I2xTcTjpci5/KDZCB8HHn7AeUsgealSSHST/rT3Jr6M8NcKs3C3ArFidnU2i32mKiM2dgFwjqpxWvulqKlH51GmJFqpXV40z/AEzf9oVyJDSiAHUEnuAUKYkdlKUqBSlKDy3Sb7m2yXL5ebsGVu8vr5Uk/wDSseWvErVfrdEuV5t8S8XKUyh56TOYS8ragCUp5h5qB3BI0ND17NXnKvtYvH4m9/cNV7GvtctX4o1/cFelo8zRbmqmcTlluh4ve+xb5NWf2Br92nvfYt8mrP7A1+7VF4V+EVYuJIykuNSbMixzJiFvTYclljxVhYT2y3nWkIQo75i0TzoG9joTVgwjjbhXEWe/CsN7EqW1H8bLL8Z6MpbG9ds32qE9o3sgc6Np6jr1FbYv3J/znxTM8U1732LfJqz+wNfu0977Fvk1Z/YGv3agMS48YJnV/RZrJkDc2e6lxcdJjvNNykt/Zlh1aAh4J9JbUrp17qrWD+EPa18HsTy7Npce1zr4XG241uivvF1xK3BpplAccOko2e/XedU5xc68+JmeLIZ4fYz0Ldgt0dwdUvRoyGXEH1pWgBST84IIqxYJdJF0sBMp0yJEaTIhqeOtuBp1SEqOgBzFKQToAb3rpXgsl5h5HZ4V1tz3jECayiQw9ylPO2obSrSgCNgjvFfrhn/Elw/rad+0LrC9VNyzM1TnEx7rnMbVupSleWxKUpQK8t0ukWy2+ROmvJjxGEFbjiu4AfMOpPqA6k9BXqrEHHW8uOzrNY0K0wUrnSE7+yKSEtD5xsrV+FCa7ND0edKv02uPosK5lXEW85Y+4lmRIs9q2Q3Fjr7N5xPoLjifOBP81JAG9Hm1uqaqw21xaluQI7ritcy3WgtSvwk9TXupX0ezao0enUtRiGOtKP8AJ61fFkP2dH0U8nrV8WQ/Z0fRUhVQvPFzEsfvLlrn3hDEppSUPHsXFNMKVrlS66lJQ2TsdFKHeK2VXYojNVWP3MzxT/k9aviyH7Oj6KeT1q+LIfs6Poqu3zjDiOOXOdb7hdizLgKQJaERXnBHCkJWlTikoISgpWnzyQnvG9ggevKOJmNYc/DZut0Sy/LQXWWmWnH1qbHe5ytpUQj/AEjofPWPL0Rn7+7ftMzxS/k9aviyH7Oj6KHHbUQR7mQ9Hp/3dH0VBcJ8ul55w7sl/nNsNSpzJccRGSUtg8yh5oJJ7gO8mrbWVFzXpiqJ2SZni77Jcbhi7iV2ae/bwkj4BKiphQ9RaPm/lAB9RFZx4fZ8zmcNbbyExbtHA8YjJO0kHoHEE96Tr8IPQ+gnA9eux3hzG8ltN1bVyhqQhl7r9kw4oIcB9ethWvWgV5Wn6DRpVuaoj78bp9pWJzsls3SlK+eiLyr7WLx+Jvf3DVexr7XLV+KNf3BVkyNlcjHro02kqcXFdSlI9JKCBVaxdaXMatKknaVRGSD6xyCvQs/kz3+y9DWa6YnkV44fcauGrWP3di93e73S7W6YuItNvmMuupebQJP2AUsbbKSQQd70KkMut978IHKbT7iYxfMPjWrG7zCkTL7BVB5X5kZLLUdoHq4EKHOVJBQOROiSa2cpTVRrDjyL3m7vBbHI+FXzGZGGSGZV4m3KCY8aOliG5HUww6fNeDiljRbJHKNnVQ2P2BVp4H4fa79jWdWfK8VuMyNDuuOWtUiRDf2s9shI5g9HdQ6Ek8qkq6g61sbb0pqio8JLjk124a47MzKImDk70RCp7CUhPK586QSEqI0SkdxJHoqx8M/4kuH9bTv2hdeuvNw1QU2GYv7ly6TlJOu8eMuDf/A//wArKvZYq74916FspSleahSlKBWEON0VUfNbVKV/m5UBbKTr7ptzmI/M6PzH1Vm+qzxAw5OaWExULSzOYWH4jy96Q4ARpWvuVAlJ+Y77wK9L7P0inRtJprr3bp/dYa/0pLjOR5Ei3z4yo8praH4rw6j0f+pJ9BHQiqaODGBA7GG2MH+r2v3a+hTVVMRNGJjv/iWC5VrlEwtm3XTKLDk9jzO5e6l3kvtO2eXL9z5caQvYLgbcS2ggKIWFgdE+mste8vgPyMsX6va/dq4ssojtIaaQlttCQlKEjQSB0AFaK7M3sa8RGP39YGHHsXmse/XHatsosTILLMEFlavGQm2pb02SPhDzDl6b69O+vBiarnw8yxm53PHbzdI92x22RWX4EJT7kR1hCg4w4kdW+YrCtnQ2Ds9OmdKVObRmKonExmfGZn3FA4CW2ZaOEGMw58R+BMajqDkaS2W3Gz2ijpST1B61f6rt+4dYtlE7x28Y7bLpL5A328uKhxfKO4bI3rqajveWwH5GWL9Xtfu1soprt0xRTETEbN/8C511PxVXFyJBb6uy5TMdA1vqpxI3+QbP5KjrFjNkw2E8zaLbCs0Ra+1cRFaSygq0BzHQA3oAb+asu8JcEffnsZJcWVMstJV4hHcSQslQ5S8oHu83YSPUpR9IrXpOkxotmble/o71p35ZfpSlfM1Kqcrh8nt3F2y93KxsrUVmLDDC2Qo9SUpdaXy7PXSSBsk661bKVsouVW/wyucKb5AXD5Z3v9BC/wAPTyAuHyzvf6CF/h6uVK3c5udnhH0Mqb5AXD5Z3v8AQQv8PTyAuHyzvf6CF/h6uVKc5udnhH0Mqgjh/IX5srKr1KZP2TX+TM8w9I52mUrH4UqB9RFWmHDYt0RmLFZRHjMoDbbTSQlKEgaAAHcK7qVrru13NlU+3oZyUpStKFKUoFKUoIXJMNs2XNIRdYKJC2wQ28CUOt77+VxJCk/kPWqU9wDtalks329R0HuQFsLA/AVNE/nJrJ9K7LWmaRYjVt1zELliz3gYPylvf5ov1FPeBg/KW9/mi/UVlOlb/iel/qen0MsWe8DB+Ut7/NF+op7wMH5S3v8ANF+orKdKfE9L/U9PoZYs94GD8pb3+aL9RXI4AwN9ckvZH/xR/wDhWUqU+J6X+p6GVKsHCDHLDIbkqYeuktshSHri52vKR3EI0EA/OEg1daUriu3rl6rWuVTM9pkpSlaUf//Z",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "def create_tool_node_with_fallback(tools: list) -> dict:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "\n",
    "\n",
    "def handle_tool_error(state: State) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "from IPython.display import Image, display\n",
    "# from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", Assistant(assistant_runnable))\n",
    "builder.add_node(\"tools\", create_tool_node_with_fallback(tools))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "# The checkpointer lets the graph persist its state\n",
    "# memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Show\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43c633d5-e7a7-4b7c-8dc7-760a3b032e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def predict_react_agent_answer(example: dict):\n",
    "    \"\"\"Use this for answer evaluation\"\"\"\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "    messages = react_graph.invoke({\"messages\": (\"user\", example[\"input\"])}, config)\n",
    "    return {\"response\": messages[\"messages\"][-1].content, \"messages\": messages}\n",
    "\n",
    "\n",
    "example = {\"input\": \"Get me information about the the types of LLM agent memory?\"}\n",
    "response = predict_react_agent_answer(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71d45f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'The types of memory used in LLM-powered autonomous agents include:\\n\\n* Maximum Inner Product Search (MIPS) memory\\n* Long-term memory module (external database) that records a comprehensive list of agents\\' experience in natural language, referred to as the \"memory stream\".\\n\\nThese memory systems are designed to enable agents to behave conditioned on past experience and interact with other agents.',\n",
       " 'messages': {'messages': [HumanMessage(content='Get me information about the the types of LLM agent memory?', id='87f1c853-e6f8-41be-aca2-a62f680be3f9'),\n",
       "   AIMessage(content='', response_metadata={'model': 'llama3.1', 'created_at': '2024-08-08T20:33:15.505703Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'retrieve_documents', 'arguments': {'query': 'types of LLM agent memory'}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 951548625, 'load_duration': 22822000, 'prompt_eval_count': 274, 'prompt_eval_duration': 563880000, 'eval_count': 22, 'eval_duration': 362132000}, id='run-5be43574-8567-4de1-846b-91fc7cbefb45-0', tool_calls=[{'name': 'retrieve_documents', 'args': {'query': 'types of LLM agent memory'}, 'id': 'd28e1cbc-fdd9-4ef0-8d9b-f4efcdb6ce04', 'type': 'tool_call'}], usage_metadata={'input_tokens': 274, 'output_tokens': 22, 'total_tokens': 296}),\n",
       "   ToolMessage(content='[Document(metadata={\\'id\\': \\'200d687a-27a7-476e-a4d8-999070af90f3\\', \\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'title\\': \"LLM Powered Autonomous Agents | Lil\\'Log\", \\'description\\': \\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\', \\'language\\': \\'en\\'}, page_content=\"LLM Powered Autonomous Agents | Lil\\'Log\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nLil\\'Log\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nPosts\\\\n\\\\n\\\\n\\\\n\\\\nArchive\\\\n\\\\n\\\\n\\\\n\\\\nSearch\\\\n\\\\n\\\\n\\\\n\\\\nTags\\\\n\\\\n\\\\n\\\\n\\\\nFAQ\\\\n\\\\n\\\\n\\\\n\\\\nemojisearch.app\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n      LLM Powered Autonomous Agents\\\\n    \\\\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\\\n\\\\n\\\\n \\\\n\\\\n\\\\nTable of Contents\\\\n\\\\n\\\\n\\\\nAgent System Overview\\\\n\\\\nComponent One: Planning\\\\n\\\\nTask Decomposition\\\\n\\\\nSelf-Reflection\\\\n\\\\n\\\\nComponent Two: Memory\\\\n\\\\nTypes of Memory\\\\n\\\\nMaximum Inner Product Search (MIPS)\\\\n\\\\n\\\\nComponent Three: Tool Use\\\\n\\\\nCase Studies\\\\n\\\\nScientific Discovery Agent\\\\n\\\\nGenerative Agents Simulation\\\\n\\\\nProof-of-Concept Examples\\\\n\\\\n\\\\nChallenges\\\\n\\\\nCitation\\\\n\\\\nReferences\"), Document(metadata={\\'id\\': \\'27256d96-6901-4c69-97b6-60a8012d9e97\\', \\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'title\\': \"LLM Powered Autonomous Agents | Lil\\'Log\", \\'description\\': \\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\', \\'language\\': \\'en\\'}, page_content=\\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview#\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\'), Document(metadata={\\'id\\': \\'d6c831be-d9cd-48b9-b1c2-b922db7e8cc4\\', \\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'title\\': \"LLM Powered Autonomous Agents | Lil\\'Log\", \\'description\\': \\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\', \\'language\\': \\'en\\'}, page_content=\\'They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\\\nGenerative Agents Simulation#\\\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\\\n\\\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\'), Document(metadata={\\'id\\': \\'4d485fab-53fd-422e-b1d6-ba9b085d37c7\\', \\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'title\\': \"LLM Powered Autonomous Agents | Lil\\'Log\", \\'description\\': \\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\', \\'language\\': \\'en\\'}, page_content=\\'Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\\\n\\\\n\\\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\\\n\\\\n\\\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\\\n\\\\n\\\\nCitation#\\\\nCited as:\\')]', name='retrieve_documents', id='4f57b557-fd7f-4bfd-a383-6728ea6959b5', tool_call_id='d28e1cbc-fdd9-4ef0-8d9b-f4efcdb6ce04'),\n",
       "   AIMessage(content='The types of memory used in LLM-powered autonomous agents include:\\n\\n* Maximum Inner Product Search (MIPS) memory\\n* Long-term memory module (external database) that records a comprehensive list of agents\\' experience in natural language, referred to as the \"memory stream\".\\n\\nThese memory systems are designed to enable agents to behave conditioned on past experience and interact with other agents.', response_metadata={'model': 'llama3.1', 'created_at': '2024-08-08T20:33:19.993477Z', 'message': {'role': 'assistant', 'content': 'The types of memory used in LLM-powered autonomous agents include:\\n\\n* Maximum Inner Product Search (MIPS) memory\\n* Long-term memory module (external database) that records a comprehensive list of agents\\' experience in natural language, referred to as the \"memory stream\".\\n\\nThese memory systems are designed to enable agents to behave conditioned on past experience and interact with other agents.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4032628333, 'load_duration': 22575375, 'prompt_eval_count': 1805, 'prompt_eval_duration': 2408997000, 'eval_count': 75, 'eval_duration': 1581937000}, id='run-b5a40e52-c47b-4f14-89c4-8c53e640be79-0', usage_metadata={'input_tokens': 1805, 'output_tokens': 75, 'total_tokens': 1880})]}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf82fa52-9e6c-4f37-94ae-91450dac602e",
   "metadata": {},
   "source": [
    "See trace with llama3.1 here:\n",
    "\n",
    "https://smith.langchain.com/public/44d0c7dd-a756-47ad-8025-ee7ae6469ecb/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd74a0b3-be40-46cd-97bf-ef9676878289",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AddableValuesDict' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m example \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet me information about the current weather in SF.\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m      2\u001b[0m response \u001b[38;5;241m=\u001b[39m predict_react_agent_answer(example)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AddableValuesDict' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "example = {\"input\": \"Get me information about the current weather in SF.\"}\n",
    "response = predict_react_agent_answer(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbb34f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in SF is mostly sunny with a temperature of 17°C or 62.5°F. There is a gentle breeze from the WSW at 9.4 mph or 15.1 kph. The humidity is around 70% and there are no precipitation chances.\n"
     ]
    }
   ],
   "source": [
    "print(response['messages']['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cac91bf-c975-44a2-a9fd-99706fee5735",
   "metadata": {},
   "source": [
    "See trace with llama3.1 here:\n",
    "\n",
    "https://smith.langchain.com/public/7a4938e3-f94f-4e04-a162-bf592fba4643/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74b813cb-18ed-42d8-b313-6ee56ded4bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'The current weather in SF is partly cloudy with a temperature of 13.5°C (56.3°F). There is no precipitation and the humidity is at 88%. The wind speed is 9.4 km/h (5.8 mph) from the WSW direction.',\n",
       " 'messages': {'messages': [HumanMessage(content='Get me information about the current weather in SF.', id='16def55f-4c02-4829-bdf1-57f35e3262d9'),\n",
       "   AIMessage(content='', response_metadata={'model': 'llama3.1', 'created_at': '2024-08-08T14:54:30.58967Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'web_search', 'arguments': {'query': 'current weather in San Francisco'}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 587123834, 'load_duration': 10742375, 'prompt_eval_count': 271, 'prompt_eval_duration': 222817000, 'eval_count': 21, 'eval_duration': 351873000}, id='run-22d367ed-da54-479f-96d2-bab30e896e3e-0', tool_calls=[{'name': 'web_search', 'args': {'query': 'current weather in San Francisco'}, 'id': 'bf0c33e3-9d7b-4fad-9569-ddce3b2a5f11', 'type': 'tool_call'}], usage_metadata={'input_tokens': 271, 'output_tokens': 21, 'total_tokens': 292}),\n",
       "   ToolMessage(content='[Document(metadata={\\'url\\': \\'https://www.weatherapi.com/\\'}, page_content=\"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1723128676, \\'localtime\\': \\'2024-08-08 07:51\\'}, \\'current\\': {\\'last_updated_epoch\\': 1723128300, \\'last_updated\\': \\'2024-08-08 07:45\\', \\'temp_c\\': 13.5, \\'temp_f\\': 56.3, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly Cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 5.8, \\'wind_kph\\': 9.4, \\'wind_degree\\': 248, \\'wind_dir\\': \\'WSW\\', \\'pressure_mb\\': 1014.0, \\'pressure_in\\': 29.93, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 88, \\'cloud\\': 26, \\'feelslike_c\\': 12.9, \\'feelslike_f\\': 55.2, \\'windchill_c\\': 12.9, \\'windchill_f\\': 55.2, \\'heatindex_c\\': 13.5, \\'heatindex_f\\': 56.3, \\'dewpoint_c\\': 11.3, \\'dewpoint_f\\': 52.3, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 4.0, \\'gust_mph\\': 8.9, \\'gust_kph\\': 14.3}}\"), Document(metadata={\\'url\\': \\'https://www.timeanddate.com/weather/usa/san-francisco/hourly\\'}, page_content=\\'Weather Today Weather Hourly 14 Day Forecast Yesterday/Past Weather Climate (Averages) Currently: 55 °F. Low clouds. (Weather station: San Francisco International Airport, USA). See more current weather.\\'), Document(metadata={\\'url\\': \\'https://www.accuweather.com/en/us/san-francisco/94103/current-weather/347629\\'}, page_content=\\'Current weather in San Francisco, CA. Check current conditions in San Francisco, CA with radar, hourly, and more.\\'), Document(metadata={\\'url\\': \\'https://forecast.weather.gov/MapClick.php?lat=37.7749&lon=-122.4194\\'}, page_content=\\'Get the latest forecast for San Francisco and the West Coast, where a late season atmospheric river event brings rain and snow.\\'), Document(metadata={\\'url\\': \\'https://www.wunderground.com/hourly/us/ca/san-francisco/94117/date/2024-08-06\\'}, page_content=\\'San Francisco Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the San Francisco area.\\')]', name='web_search', id='e585b895-56b7-48a4-8c2a-5da3279d9625', tool_call_id='bf0c33e3-9d7b-4fad-9569-ddce3b2a5f11'),\n",
       "   AIMessage(content='The current weather in SF is partly cloudy with a temperature of 13.5°C (56.3°F). There is no precipitation and the humidity is at 88%. The wind speed is 9.4 km/h (5.8 mph) from the WSW direction.', response_metadata={'model': 'llama3.1', 'created_at': '2024-08-08T14:54:36.877931Z', 'message': {'role': 'assistant', 'content': 'The current weather in SF is partly cloudy with a temperature of 13.5°C (56.3°F). There is no precipitation and the humidity is at 88%. The wind speed is 9.4 km/h (5.8 mph) from the WSW direction.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2316560792, 'load_duration': 25304750, 'prompt_eval_count': 826, 'prompt_eval_duration': 1235488000, 'eval_count': 58, 'eval_duration': 1043632000}, id='run-b468cf9f-49ae-4ac3-8ead-f85d9754af62-0', usage_metadata={'input_tokens': 826, 'output_tokens': 58, 'total_tokens': 884})]}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-llama3",
   "language": "python",
   "name": "oreilly-llama3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
