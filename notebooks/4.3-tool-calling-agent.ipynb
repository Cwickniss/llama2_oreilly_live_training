{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29317d99-1605-410d-b838-fbc3469e4856",
   "metadata": {},
   "source": [
    "# Local Tool Calling Agent\n",
    "\n",
    "Here, we'll build a [tool calling agent](https://python.langchain.com/v0.1/docs/modules/agents/agent_types/tool_calling/) using local models.\n",
    "\n",
    "We'll use the [new fine-tune from Groq](https://wow.groq.com/introducing-llama-3-groq-tool-use-models/) with tool calling via Ollama:\n",
    "\n",
    "Access the model:\n",
    "\n",
    "```\n",
    "ollama pull llama3-groq-tool-use\n",
    "ollama pull llama3.1\n",
    "```\n",
    "\n",
    "And also, we'll use the Ollama partner package.\n",
    "\n",
    "This notebook accompanies the video here:\n",
    "\n",
    "https://www.youtube.com/watch?v=Nfk99Fz8H9k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "666175b4-f056-489d-9d94-a0a666270794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-xxx\"\n",
    "\n",
    "# os.environ[\"TAVILY_API_KEY\"] = \"tvly-xxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "120c1da8-e45e-4ffa-9ac1-a536026c7e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.5.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/greatmaster/miniconda3/envs/oreilly-agents/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.14.0-cp311-cp311-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.5.1-cp311-cp311-macosx_12_0_arm64.whl (11.0 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.14.0-cp311-cp311-macosx_14_0_arm64.whl (23.1 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.1 scipy-1.14.0 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-ollama langchain-openai langgraph\n",
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c0504b-007a-4af6-9976-c7294ed26b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /// LLM ///\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    # model=\"llama3-groq-tool-use\",\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe7e4451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Tom Cruise is a renowned American actor known for his versatility and range in various film genres. Here are some key facts about him:\\n\\n**Early Life**\\n\\nThomas Cruise Mapother IV was born on July 3, 1962, in Syracuse, New York. He grew up with three siblings and was raised by his mother, Mary Lee Pfeiffer, after his father abandoned the family when Tom was just a child.\\n\\n**Career**\\n\\nCruise began his acting career at a young age, appearing in television shows and films throughout the 1980s. His breakthrough role came in 1981 with the film \"Taps,\" which led to more prominent roles in films like \"The Outsiders\" (1983) and \"Legend\" (1985).\\n\\n**Blockbuster Success**\\n\\nCruise\\'s career gained momentum in the late 1980s and early 1990s with films like \"Top Gun\" (1986), \"Rain Man\" (1988), and \"Born on the Fourth of July\" (1989). These roles cemented his status as a leading man in Hollywood.\\n\\n**Action Hero**\\n\\nIn the 1990s, Cruise became synonymous with action-packed blockbusters. Some notable films from this period include:\\n\\n* \"A Few Good Men\" (1992)\\n* \"The Firm\" (1993)\\n* \"Interview with the Vampire\" (1994)\\n* \"Mission: Impossible\" (1996) - which he also produced\\n\\n**Recent Films**\\n\\nIn recent years, Cruise has continued to take on diverse roles in films like:\\n\\n* \"Minority Report\" (2002)\\n* \"Collateral\" (2004)\\n* \"Tropic Thunder\" (2008)\\n* \"Edge of Tomorrow\" (2014)\\n* \"The Mummy\" (2017)\\n\\n**Personal Life**\\n\\nCruise has been married three times: to actress Mimi Rogers (1987-1990), Nicole Kidman (1990-2001), and Katie Holmes (2006-2012). He has two children with his first wife, Isabella and Connor.\\n\\n**Philanthropy**\\n\\nCruise is known for his philanthropic efforts, particularly in the area of education. In 2005, he donated $50 million to the University of Southern California\\'s (USC) film school, which was renamed the Tom Cruise Endowed Chair in Film Production.\\n\\n**Awards and Recognition**\\n\\nThroughout his career, Cruise has received numerous awards and nominations, including:\\n\\n* Three Golden Globe Awards\\n* Three Academy Award nominations\\n* A star on the Hollywood Walk of Fame\\n\\nOverall, Tom Cruise is a talented actor who has consistently demonstrated his range and versatility in various film genres.', response_metadata={'model': 'llama3.2', 'created_at': '2024-12-02T14:42:43.284444Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 6261556042, 'load_duration': 563808917, 'prompt_eval_count': 32, 'prompt_eval_duration': 157000000, 'eval_count': 546, 'eval_duration': 5539000000}, id='run-b04a15ed-42f9-447c-820c-99902c48a5a5-0', usage_metadata={'input_tokens': 32, 'output_tokens': 546, 'total_tokens': 578})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hi, tell me about Tom Cruise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7fd03f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', response_metadata={'model': 'llama3.2', 'created_at': '2024-12-02T14:42:46.203184Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'retrieve_guest_number', 'arguments': {'guest_name': 'Bob'}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 402030333, 'load_duration': 29962750, 'prompt_eval_count': 171, 'prompt_eval_duration': 191000000, 'eval_count': 19, 'eval_duration': 179000000}, id='run-e7dc6c8b-47bd-497a-845c-8afad2fa7c66-0', tool_calls=[{'name': 'retrieve_guest_number', 'args': {'guest_name': 'Bob'}, 'id': '9125d010-5ac0-4c4e-8912-153d5345e909', 'type': 'tool_call'}], usage_metadata={'input_tokens': 171, 'output_tokens': 19, 'total_tokens': 190})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_guest_number(guest_name: str) -> int:\n",
    "    \"\"\"Given a guest name this function returns the guest number.\"\"\"\n",
    "    return [\"Alice\", \"Bob\", \"Charlie\", \"David\"].index(guest_name) + 1\n",
    "\n",
    "\n",
    "tools = [retrieve_guest_number]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "llm_with_tools.invoke(\"Use your tools to figure out the guest number of Bob.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d83702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# /// Retriever tool ///\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# List of URLs to load documents from\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "# Load documents from the URLs\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# Initialize a text splitter with specified chunk size and overlap\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "\n",
    "# Split the documents into chunks\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add the document chunks to the \"vector store\" using OpenAIEmbeddings\n",
    "vectorstore = SKLearnVectorStore.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever(k=4)\n",
    "\n",
    "\n",
    "# Define a tool, which we will connect to our agent\n",
    "def retrieve_documents(query: str) -> list:\n",
    "    \"\"\"Retrieve documents from the vector store based on the query.\"\"\"\n",
    "    return retriever.invoke(query)\n",
    "\n",
    "\n",
    "# /// Search Tool\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "web_search_tool = TavilySearchResults()\n",
    "\n",
    "\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Run web search on the question.\"\"\"\n",
    "    web_results = web_search_tool.invoke({\"query\": query})\n",
    "    return [\n",
    "        Document(page_content=d[\"content\"], metadata={\"url\": d[\"url\"]})\n",
    "        for d in web_results\n",
    "    ]\n",
    "\n",
    "# Tool list\n",
    "tools = [retrieve_documents, web_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aecdb3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3.2\", temperature=0)\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "189e71a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', response_metadata={'model': 'llama3.2', 'created_at': '2024-12-02T14:43:00.290833Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'web_search', 'arguments': {'query': 'funniest jokes about cat people'}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 416023791, 'load_duration': 29556541, 'prompt_eval_count': 217, 'prompt_eval_duration': 172000000, 'eval_count': 22, 'eval_duration': 213000000}, id='run-189d380c-5555-4420-9501-47eba1a54385-0', tool_calls=[{'name': 'web_search', 'args': {'query': 'funniest jokes about cat people'}, 'id': '203cdf53-d7f1-45ce-bd5f-8bbf2d2b19ff', 'type': 'tool_call'}], usage_metadata={'input_tokens': 217, 'output_tokens': 22, 'total_tokens': 239})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"Use your search tool to search the web for the funniest jokes about cat people.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30052f47-2b5d-46f5-9873-eb716145cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        \"\"\"\n",
    "        Initialize the Assistant with a runnable object.\n",
    "\n",
    "        Args:\n",
    "            runnable (Runnable): The runnable instance to invoke.\n",
    "        \"\"\"\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        \"\"\"\n",
    "        Call method to invoke the LLM and handle its responses.\n",
    "        Re-prompt the assistant if the response is not a tool call or meaningful text.\n",
    "\n",
    "        Args:\n",
    "            state (State): The current state containing messages.\n",
    "            config (RunnableConfig): The configuration for the runnable.\n",
    "\n",
    "        Returns:\n",
    "            dict: The final state containing the updated messages.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)  # Invoke the LLM\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n",
    "# Create the primary assistant prompt template\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant tasked with answering user questions. \"\n",
    "            \"You have access to two tools: retrieve_documents and web_search. \"\n",
    "            \"For any user questions about LLM agents, use the retrieve_documents tool to get information for a vectorstore. \"\n",
    "            \"For any other questions, such as questions about current events, use the web_search tool to get information from the web. \",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Prompt our LLM and bind tools\n",
    "assistant_runnable = primary_assistant_prompt | llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40504a0b-8a99-4420-a6bf-561c62e893d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "def create_tool_node_with_fallback(tools: list) -> dict:\n",
    "    return ToolNode(tools).with_fallbacks(\n",
    "        [RunnableLambda(handle_tool_error)], exception_key=\"error\"\n",
    "    )\n",
    "\n",
    "\n",
    "def handle_tool_error(state: State) -> dict:\n",
    "    error = state.get(\"error\")\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=f\"Error: {repr(error)}\\n please fix your mistakes.\",\n",
    "                tool_call_id=tc[\"id\"],\n",
    "            )\n",
    "            for tc in tool_calls\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "from IPython.display import Image, display\n",
    "# from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", Assistant(assistant_runnable))\n",
    "builder.add_node(\"tools\", create_tool_node_with_fallback(tools))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "# The checkpointer lets the graph persist its state\n",
    "# memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Show\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43c633d5-e7a7-4b7c-8dc7-760a3b032e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def predict_react_agent_answer(example: dict):\n",
    "    \"\"\"Use this for answer evaluation\"\"\"\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "    messages = react_graph.invoke({\"messages\": (\"user\", example[\"input\"])}, config)\n",
    "    return {\"response\": messages[\"messages\"][-1].content, \"messages\": messages}\n",
    "\n",
    "\n",
    "example = {\"input\": \"Get me information about the the types of LLM agent memory?\"}\n",
    "response = predict_react_agent_answer(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71d45f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'The provided text is a collection of articles and research papers related to Large Language Models (LLMs) and their applications in autonomous agents. The main topics covered include:\\n\\n1. **Planning**: Breaking down complex tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes, and refining them for future steps to improve the quality of final results.\\n3. **Memory**: Utilizing short-term memory for in-context learning (e.g., prompt engineering) and long-term memory for retaining and recalling information over extended periods, often leveraging external vector stores and fast retrieval.\\n4. **Tool use**: Learning to call external APIs for extra information that is missing from the model weights, including current information, code execution capability, access to proprietary information sources, and more.\\n\\nThe articles also discuss the potential risks of LLM-powered autonomous agents, particularly in relation to illicit drugs and bioweapons. Additionally, there is a mention of a simulation experiment called \"Generative Agents\" where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment.\\n\\nThe text also mentions several proof-of-concept demos, including AutoGPT, GPT-Engineer, and BabyAGI, which demonstrate the potential of LLMs as powerful general problem solvers.',\n",
       " 'messages': {'messages': [HumanMessage(content='Get me information about the the types of LLM agent memory?', id='6c98f1a7-f477-4400-a390-3c4096b01746'),\n",
       "   AIMessage(content='', response_metadata={'model': 'llama3.2', 'created_at': '2024-12-02T14:43:22.958205Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'retrieve_documents', 'arguments': {'query': 'LLM agent memory types'}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 806418792, 'load_duration': 31222917, 'prompt_eval_count': 282, 'prompt_eval_duration': 265000000, 'eval_count': 21, 'eval_duration': 205000000}, id='run-66ca77d0-dca7-4fd0-bbd8-49ed1cf2273e-0', tool_calls=[{'name': 'retrieve_documents', 'args': {'query': 'LLM agent memory types'}, 'id': '628f1506-34f5-4b3e-9e60-bbd8c3d3851e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 282, 'output_tokens': 21, 'total_tokens': 303}),\n",
       "   ToolMessage(content='[Document(metadata={\\'id\\': \\'193abd05-e0fc-4eb8-838b-076f03cccf80\\', \\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'title\\': \"LLM Powered Autonomous Agents | Lil\\'Log\", \\'description\\': \\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\\\n\\\\n\\\\n\\\\n\\\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\', \\'language\\': \\'en\\'}, page_content=\"LLM Powered Autonomous Agents | Lil\\'Log\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nLil\\'Log\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n|\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nPosts\\\\n\\\\n\\\\n\\\\n\\\\nArchive\\\\n\\\\n\\\\n\\\\n\\\\nSearch\\\\n\\\\n\\\\n\\\\n\\\\nTags\\\\n\\\\n\\\\n\\\\n\\\\nFAQ\\\\n\\\\n\\\\n\\\\n\\\\nemojisearch.app\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n      LLM Powered Autonomous Agents\\\\n    \\\\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\\\n\\\\n\\\\n \\\\n\\\\n\\\\nTable of Contents\\\\n\\\\n\\\\n\\\\nAgent System Overview\\\\n\\\\nComponent One: Planning\\\\n\\\\nTask Decomposition\\\\n\\\\nSelf-Reflection\\\\n\\\\n\\\\nComponent Two: Memory\\\\n\\\\nTypes of Memory\\\\n\\\\nMaximum Inner Product Search (MIPS)\\\\n\\\\n\\\\nComponent Three: Tool Use\\\\n\\\\nCase Studies\\\\n\\\\nScientific Discovery Agent\\\\n\\\\nGenerative Agents Simulation\\\\n\\\\nProof-of-Concept Examples\\\\n\\\\n\\\\nChallenges\\\\n\\\\nCitation\\\\n\\\\nReferences\"), Document(metadata={\\'id\\': \\'db4b11e0-61e4-42dd-a97e-2ac1cfbaa8fe\\', \\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'title\\': \"LLM Powered Autonomous Agents | Lil\\'Log\", \\'description\\': \\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\\\n\\\\n\\\\n\\\\n\\\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\', \\'language\\': \\'en\\'}, page_content=\\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview#\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\'), Document(metadata={\\'id\\': \\'5665c6bb-d144-452d-a48f-36024ac3f5a2\\', \\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'title\\': \"LLM Powered Autonomous Agents | Lil\\'Log\", \\'description\\': \\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\\\n\\\\n\\\\n\\\\n\\\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\', \\'language\\': \\'en\\'}, page_content=\\'They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\\\nGenerative Agents Simulation#\\\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\\\n\\\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\'), Document(metadata={\\'id\\': \\'33a35e5d-c920-4257-b442-a62993ef557f\\', \\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'title\\': \"LLM Powered Autonomous Agents | Lil\\'Log\", \\'description\\': \\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview\\\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\\\n\\\\nPlanning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\\\n\\\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\\\n\\\\n\\\\nTool use\\\\n\\\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\\\n\\\\n\\\\n\\\\n\\\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\', \\'language\\': \\'en\\'}, page_content=\\'Weng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\\')]', name='retrieve_documents', id='3bbe11fe-4b40-4103-ac51-05f24423dd0a', tool_call_id='628f1506-34f5-4b3e-9e60-bbd8c3d3851e'),\n",
       "   AIMessage(content='The provided text is a collection of articles and research papers related to Large Language Models (LLMs) and their applications in autonomous agents. The main topics covered include:\\n\\n1. **Planning**: Breaking down complex tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes, and refining them for future steps to improve the quality of final results.\\n3. **Memory**: Utilizing short-term memory for in-context learning (e.g., prompt engineering) and long-term memory for retaining and recalling information over extended periods, often leveraging external vector stores and fast retrieval.\\n4. **Tool use**: Learning to call external APIs for extra information that is missing from the model weights, including current information, code execution capability, access to proprietary information sources, and more.\\n\\nThe articles also discuss the potential risks of LLM-powered autonomous agents, particularly in relation to illicit drugs and bioweapons. Additionally, there is a mention of a simulation experiment called \"Generative Agents\" where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment.\\n\\nThe text also mentions several proof-of-concept demos, including AutoGPT, GPT-Engineer, and BabyAGI, which demonstrate the potential of LLMs as powerful general problem solvers.', response_metadata={'model': 'llama3.2', 'created_at': '2024-12-02T14:43:28.529099Z', 'message': {'role': 'assistant', 'content': 'The provided text is a collection of articles and research papers related to Large Language Models (LLMs) and their applications in autonomous agents. The main topics covered include:\\n\\n1. **Planning**: Breaking down complex tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\n2. **Reflection and refinement**: Self-criticism and self-reflection over past actions, learning from mistakes, and refining them for future steps to improve the quality of final results.\\n3. **Memory**: Utilizing short-term memory for in-context learning (e.g., prompt engineering) and long-term memory for retaining and recalling information over extended periods, often leveraging external vector stores and fast retrieval.\\n4. **Tool use**: Learning to call external APIs for extra information that is missing from the model weights, including current information, code execution capability, access to proprietary information sources, and more.\\n\\nThe articles also discuss the potential risks of LLM-powered autonomous agents, particularly in relation to illicit drugs and bioweapons. Additionally, there is a mention of a simulation experiment called \"Generative Agents\" where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment.\\n\\nThe text also mentions several proof-of-concept demos, including AutoGPT, GPT-Engineer, and BabyAGI, which demonstrate the potential of LLMs as powerful general problem solvers.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5151261084, 'load_duration': 23951250, 'prompt_eval_count': 2048, 'prompt_eval_duration': 1346000000, 'eval_count': 283, 'eval_duration': 3773000000}, id='run-fa53b6e1-ac72-4d72-b363-d94eaa2409f8-0', usage_metadata={'input_tokens': 2048, 'output_tokens': 283, 'total_tokens': 2331})]}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd74a0b3-be40-46cd-97bf-ef9676878289",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = {\"input\": \"Get me information about the current weather in SF.\"}\n",
    "response = predict_react_agent_answer(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbb34f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in San Francisco is partly cloudy with a temperature of 7.8°C (46°F). There is a gentle breeze blowing at 5.8 mph (9.4 km/h) from the northeast direction. The humidity is 86%, and the pressure is 1022 mb.\n"
     ]
    }
   ],
   "source": [
    "print(response['messages']['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cac91bf-c975-44a2-a9fd-99706fee5735",
   "metadata": {},
   "source": [
    "See trace with llama3.1 here:\n",
    "\n",
    "https://smith.langchain.com/public/7a4938e3-f94f-4e04-a162-bf592fba4643/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74b813cb-18ed-42d8-b313-6ee56ded4bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'The current weather in San Francisco is partly cloudy with a temperature of 7.8°C (46°F). There is a gentle breeze blowing at 5.8 mph (9.4 km/h) from the northeast direction. The humidity is 86%, and the pressure is 1022 mb.',\n",
       " 'messages': {'messages': [HumanMessage(content='Get me information about the current weather in SF.', id='56eae6bc-ded0-4510-8b60-a5b869f80460'),\n",
       "   AIMessage(content='', response_metadata={'model': 'llama3.2', 'created_at': '2024-12-02T14:43:43.744656Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'web_search', 'arguments': {'query': 'current weather in San Francisco'}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 497252333, 'load_duration': 29821458, 'prompt_eval_count': 279, 'prompt_eval_duration': 264000000, 'eval_count': 21, 'eval_duration': 201000000}, id='run-cb2bf116-af03-4abe-aa2e-964d9ef13e3b-0', tool_calls=[{'name': 'web_search', 'args': {'query': 'current weather in San Francisco'}, 'id': '0423c2e8-3e3c-4424-9d16-2a9b2fac8068', 'type': 'tool_call'}], usage_metadata={'input_tokens': 279, 'output_tokens': 21, 'total_tokens': 300}),\n",
       "   ToolMessage(content='[Document(metadata={\\'url\\': \\'https://www.weatherapi.com/\\'}, page_content=\"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1733150294, \\'localtime\\': \\'2024-12-02 06:38\\'}, \\'current\\': {\\'last_updated_epoch\\': 1733149800, \\'last_updated\\': \\'2024-12-02 06:30\\', \\'temp_c\\': 7.8, \\'temp_f\\': 46.0, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 5.8, \\'wind_kph\\': 9.4, \\'wind_degree\\': 43, \\'wind_dir\\': \\'NE\\', \\'pressure_mb\\': 1022.0, \\'pressure_in\\': 30.18, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 86, \\'cloud\\': 25, \\'feelslike_c\\': 6.1, \\'feelslike_f\\': 43.0, \\'windchill_c\\': 11.0, \\'windchill_f\\': 51.8, \\'heatindex_c\\': 11.3, \\'heatindex_f\\': 52.3, \\'dewpoint_c\\': 8.6, \\'dewpoint_f\\': 47.5, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 0.0, \\'gust_mph\\': 11.5, \\'gust_kph\\': 18.6}}\"), Document(metadata={\\'url\\': \\'https://www.accuweather.com/en/us/san-francisco/94103/current-weather/347629\\'}, page_content=\\'San Francisco, CA Current Weather | AccuWeather Winter Weather Storm with wind, snow and some rain brewing for Midwest, East 7 hours ago Hurricane Sara moves into Gulf, set to bring heavy rain to South, Southeast 4 hours ago Astronomy Moon to align with Jupiter, Mars on Monday night 4 hours ago Severe Weather Severe thunderstorms to rumble through southern Plains on Monday 2 hours ago Winter Weather More storms with rain, mountain snow lining up for northwestern US 7 hours ago  More Stories AccuWeather Ready Business Health Hurricane Leisure and Recreation Severe Weather Space and Astronomy Sports Travel Weather News Winter Center AccuWeather Ready Business Health Hurricane Leisure and Recreation Severe Weather Space and Astronomy Sports Travel Weather News Winter Center\\'), Document(metadata={\\'url\\': \\'https://www.timeanddate.com/weather/usa/san-francisco\\'}, page_content=\\'Home \\\\xa0 Weather \\\\xa0 USA \\\\xa0 San Francisco Weather in San Francisco, California, USA Weather 58\\\\xa0°F Forecast: 60 / 47\\\\xa0°F Current Time:   Nov 18, 2024 at 11:27:22 am See more hour-by-hour weather Forecast for the next 48 hours Forecast                           ↑   WNW ↑   WNW * Updated Monday, November 18, 2024 5:02:53 am San Francisco time - Weather by CustomWeather, © 2024 59 / 46\\\\xa0°F More weather last week 59\\\\xa0°F 59\\\\xa0°F 57\\\\xa0°F More weather in USA 60 / 47\\\\xa0°F 58 / 43\\\\xa0°F 60 / 53\\\\xa0°F 64 / 57\\\\xa0°F 64 / 58\\\\xa0°F 60 / 47\\\\xa0°F 54 / 47\\\\xa0°F 53 / 47\\\\xa0°F Sun & Moon times precise to the second. Privacy Policy Weather\\'), Document(metadata={\\'url\\': \\'https://www.timeanddate.com/weather/@z-us-94141/ext\\'}, page_content=\\'San Francisco, USA 14 day weather forecast Time Zone News Calendar & Holiday News Time Zones Time Zones Home Time Zone News Calendar & Holiday News Weather Sun & Moon Home Sun Calculator Moon Calculator Calculators Calculators Home Home \\\\xa0 Weather \\\\xa0 San Francisco \\\\xa0 Two-week forecast Weather Time Zone Last 2 weeks of weather Nov 15 |  | 61 / 49\\\\xa0°F | Sunny. Nov 25 |  | 60 / 51\\\\xa0°F | Sunny. Nov 26 |  | 56 / 48\\\\xa0°F | Sunny. | * Updated Friday, November 15, 2024 1:24:06 pm San Francisco time - Weather by CustomWeather, © 2024 | Hour-by-hour weather for San Francisco next 7 days Sun & Moon times precise to the second. Time Zones Weather Calculators\\'), Document(metadata={\\'url\\': \\'https://www.wunderground.com/weather/us/ca/san-francisco\\'}, page_content=\\'San Francisco, CA Weather Conditions | Weather Underground San Francisco, CA Weather Conditions_star_rate__home_ 56\\\\xa0°F South of Market Station|Report Report Station You are about to report this weather station for bad data. Personal Weather Station Nearby Weather Stations Nearby Weather Stations The time period when the sun is no more than 6 degrees below the horizon at either sunrise or sunset. The time period when the sun is between 6 and 12 degrees below the horizon at either sunrise or sunset. The time period when the sun is between 12 and 18 degrees below the horizon at either sunrise or sunset. The sun does not contribute to the illumination of the sky before this time in the morning, or after this time in the evening.\\')]', name='web_search', id='bf221689-3e4a-4ac5-8086-191b21f3c784', tool_call_id='0423c2e8-3e3c-4424-9d16-2a9b2fac8068'),\n",
       "   AIMessage(content='The current weather in San Francisco is partly cloudy with a temperature of 7.8°C (46°F). There is a gentle breeze blowing at 5.8 mph (9.4 km/h) from the northeast direction. The humidity is 86%, and the pressure is 1022 mb.', response_metadata={'model': 'llama3.2', 'created_at': '2024-12-02T14:43:48.392313Z', 'message': {'role': 'assistant', 'content': 'The current weather in San Francisco is partly cloudy with a temperature of 7.8°C (46°F). There is a gentle breeze blowing at 5.8 mph (9.4 km/h) from the northeast direction. The humidity is 86%, and the pressure is 1022 mb.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1676940667, 'load_duration': 30276750, 'prompt_eval_count': 1380, 'prompt_eval_duration': 897000000, 'eval_count': 62, 'eval_duration': 743000000}, id='run-0f3ab4dc-2698-4905-946e-443617053012-0', usage_metadata={'input_tokens': 1380, 'output_tokens': 62, 'total_tokens': 1442})]}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-llama3",
   "language": "python",
   "name": "oreilly-llama3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
