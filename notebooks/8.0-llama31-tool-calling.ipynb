{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3.1 Tool Calling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets-resources/llama-tool-calling-flow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U transformers accelerate bitsandbytes huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPT = \"\"\" <|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an information extraction tool. Extract all names and dates mentioned in the following text. <|eot_id|> <|start_header_id|>user<|end_header_id|> Text: \"John Doe was born on January 1, 1990. Jane Smith graduated on June 15, 2010.\" <|eot_id|> <|start_header_id|>assistant<|end_header_id|> \"\"\"\n",
    "PROMPT = \"hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " system You are an information extraction tool. Extract all names and dates mentioned in the following text.  user Text: \"John Doe was born on January 1, 1990. Jane Smith graduated on June 15, 2010.\"  assistant  Here are the extracted names and dates:\n",
      "\n",
      " Names:\n",
      "1. John Doe\n",
      "2. Jane Smith\n",
      "\n",
      " Dates:\n",
      "1. January 1, 1990\n",
      "2. June 15, 2010\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(PROMPT, return_tensors=\"pt\")\n",
    "response = model.generate(**input_ids, max_length=512)\n",
    "extracted_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool-Calling with Llama 3.1\n",
    "\n",
    "Llama 3.1 can also use tool-calling capabilities to execute specific functions. For instance, you can create a function to execute Python code within a Jupyter Notebook environment. This can be useful for running more complex extraction logic or data processing scripts directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"you are a python data scientist. You run python code to solve tasks. Execute the code in Jupyter Notebook cells.\"\"\"\n",
    "tools = [     {         \"type\": \"function\",         \"function\": {             \"name\": \"execute_python\",             \"description\": \"Execute python code in a Jupyter notebook cell and returns any result, stdout, stderr, display_data, and error.\",             \"parameters\": {                 \"type\": \"object\",                 \"properties\": {                     \"code\": {                         \"type\": \"string\",                         \"description\": \"The python code to execute in a single cell.\",                     }                 },                 \"required\": [\"code\"],             },         },     } ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: e2b_code_interpreter in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (0.0.9)\n",
      "Requirement already satisfied: e2b>=0.17.1 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from e2b_code_interpreter) (0.17.1)\n",
      "Requirement already satisfied: pydantic<3,>1 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from e2b_code_interpreter) (2.8.2)\n",
      "Collecting websocket-client<2.0.0,>=1.7.0 (from e2b_code_interpreter)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: aenum>=3.1.11 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from e2b>=0.17.1->e2b_code_interpreter) (3.1.15)\n",
      "Requirement already satisfied: aiohttp>=3.8.4 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from e2b>=0.17.1->e2b_code_interpreter) (3.9.5)\n",
      "Requirement already satisfied: jsonrpcclient>=4.0.3 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from e2b>=0.17.1->e2b_code_interpreter) (4.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from e2b>=0.17.1->e2b_code_interpreter) (2.9.0.post0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from e2b>=0.17.1->e2b_code_interpreter) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from e2b>=0.17.1->e2b_code_interpreter) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.25.3 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from e2b>=0.17.1->e2b_code_interpreter) (2.2.2)\n",
      "Requirement already satisfied: websockets>=11.0.3 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from e2b>=0.17.1->e2b_code_interpreter) (11.0.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from pydantic<3,>1->e2b_code_interpreter) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from pydantic<3,>1->e2b_code_interpreter) (2.20.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from aiohttp>=3.8.4->e2b>=0.17.1->e2b_code_interpreter) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from aiohttp>=3.8.4->e2b>=0.17.1->e2b_code_interpreter) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from aiohttp>=3.8.4->e2b>=0.17.1->e2b_code_interpreter) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from aiohttp>=3.8.4->e2b>=0.17.1->e2b_code_interpreter) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from aiohttp>=3.8.4->e2b>=0.17.1->e2b_code_interpreter) (1.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->e2b>=0.17.1->e2b_code_interpreter) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from requests>=2.31.0->e2b>=0.17.1->e2b_code_interpreter) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from requests>=2.31.0->e2b>=0.17.1->e2b_code_interpreter) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/greatmaster/miniconda3/envs/test-env/lib/python3.11/site-packages (from requests>=2.31.0->e2b>=0.17.1->e2b_code_interpreter) (2024.7.4)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: websocket-client\n",
      "Successfully installed websocket-client-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install e2b_code_interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import e2b_code_interpreter\n",
    "\n",
    "def code_interpret(e2b_code_interpreter, code):\n",
    "    exec = e2b_code_interpreter.notebook.exec_cell(\n",
    "        code,\n",
    "        on_stderr=lambda stderr: print(\"[Code Interpreter]\", stderr),\n",
    "        on_stdout=lambda stdout: print(\"[Code Interpreter]\", stdout)\n",
    "    )\n",
    "    if exec.error:\n",
    "        print(\"[Code Interpreter ERROR]\", exec.error)\n",
    "    else:\n",
    "        return exec.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\" <|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an AI assistant with the ability to call external functions to get real-time data. The following functions are available for you to use:  - `get_weather`: Gets the current weather for a given location.   Parameters:   - `location`: The city to get the weather for.  - `get_time`: Gets the current time for a given location.   Parameters:   - `location`: The city to get the time for.  To call a function, use the following syntax: <function=function_name>{\"parameter1\": \"value1\", \"parameter2\": \"value2\"}</function> <|eot_id|> \"\"\"\n",
    "USER_PROMPT = \"\"\" <|start_header_id|>user<|end_header_id|> What is the weather in San Francisco? <|eot_id|> \"\"\"\n",
    "\n",
    "PROMPT = SYSTEM_PROMPT + USER_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(location):\n",
    "    return f\"The weather in {location} is sunny.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|> <|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an AI assistant with the ability to call external functions to get real-time data. The following functions are available for you to use:  - `get_weather`: Gets the current weather for a given location.   Parameters:   - `location`: The city to get the weather for.  - `get_time`: Gets the current time for a given location.   Parameters:   - `location`: The city to get the time for.  To call a function, use the following syntax: <function=function_name>{\"parameter1\": \"value1\", \"parameter2\": \"value2\"}</function> <|eot_id|>  <|start_header_id|>user<|end_header_id|> What is the weather in San Francisco? <|eot_id|> assistant<|end_header_id|>\n",
      "\n",
      "{get_weather(location=\"San Francisco\"}<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(PROMPT, return_tensors=\"pt\")\n",
    "response = model.generate(**input_ids, max_length=512)\n",
    "extracted_text = tokenizer.decode(response[0])\n",
    "print(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating into a FastAPI app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Request\n",
    "import uvicorn\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/chat\")\n",
    "async def chat(request: Request):\n",
    "    data = await request.json()\n",
    "    user_message = data['message']\n",
    "    prompt = f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>{user_message}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    response = model.generate(**input_ids, max_length=512)\n",
    "    generated_text = tokenizer.decode(response[0], skip_special_tokens=True)\n",
    "    return {\"response\": generated_text}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-env",
   "language": "python",
   "name": "test-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
