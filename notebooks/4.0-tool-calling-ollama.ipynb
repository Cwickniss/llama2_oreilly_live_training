{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.1', 'created_at': '2024-08-08T14:46:19.155608Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'get_current_weather', 'arguments': {'city': 'Sydney'}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 490881000, 'load_duration': 25061792, 'prompt_eval_count': 157, 'prompt_eval_duration': 164402000, 'eval_count': 19, 'eval_duration': 298979000}\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import requests\n",
    "\n",
    "def get_current_weather(city):\n",
    "    \"\"\"\n",
    "    Get the current weather for a city.\n",
    "\n",
    "    Parameters:\n",
    "    city (str): The name of the city.\n",
    "\n",
    "    Returns:\n",
    "    str: The current temperature in the specified city.\n",
    "    \"\"\"\n",
    "    return f\"The current temperature in {city} is sunny\"\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"\"\n",
    "    model=\"llama3.1\",\n",
    "    messages=[{'role': 'system', 'content': 'You are a helpful assistant that helps users with information. When users ask about the weather you use the get_current_weather tool to answer.'},\n",
    "        {'role': 'user', 'content': 'What is the weather in Sydney?'}],\n",
    "    tools=[{\n",
    "        'type': 'function',\n",
    "        'name': 'get_current_weather',\n",
    "        'description': 'Get the current weather for a city',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'city': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The name of the city',\n",
    "                    'required': ['city']\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current temperature in Sydney is sunny\n"
     ]
    }
   ],
   "source": [
    "def run_tool_calls(response):\n",
    "    tool_calls = response['message']['tool_calls']\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call['function']['name']\n",
    "        arguments = tool_call['function']['arguments']\n",
    "        if function_name == 'get_current_weather':\n",
    "            city = arguments['city']\n",
    "            temperature = get_current_weather(city)\n",
    "            print(temperature)\n",
    "\n",
    "run_tool_calls(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using OpenAI API + Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-839', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content='', refusal=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_fggot8j5', function=Function(arguments='{\"city\":\"San Francisco\"}', name='check_weather'), type='function')]))], created=1723128595, model='llama3.1', object='chat.completion', service_tier=None, system_fingerprint='fp_ollama', usage=CompletionUsage(completion_tokens=18, prompt_tokens=169, total_tokens=187))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused\n",
    ")\n",
    "\n",
    "\n",
    "def check_weather(city: str) -> str:\n",
    "    \"\"\"Function that checks the weather.\"\"\"\n",
    "    return \"It's sunny in \" + city\n",
    "    \n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather in San Francisco?\"}\n",
    "]\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"check_weather\",\n",
    "            \"description\": \"Get the current weather for a given city.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"city\"],\n",
    "            },\n",
    "        }\n",
    "    },]\n",
    "\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(model=\"llama3.1\", messages=messages, tools=tools)\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-llama3",
   "language": "python",
   "name": "oreilly-llama3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
