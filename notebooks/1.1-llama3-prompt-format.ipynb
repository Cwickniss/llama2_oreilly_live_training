{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama3 model card explanation to give context for the weird prompts in langchain rag setups\n",
    "\n",
    "[Meta Llama 3 | Model Cards and Prompt formats](https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3/)\n",
    "\n",
    "[Official model card](https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md)\n",
    "\n",
    "# **Meta Llama 3**\n",
    "\n",
    "## **Model Card**\n",
    "\n",
    "You can find details about this model in the [model card](https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md).\n",
    "\n",
    "## **Special Tokens used with Meta Llama 3**\n",
    "\n",
    "**<|begin_of_text|>**: This is equivalent to the BOS token\n",
    "\n",
    "**<|eot_id|>**: This signifies the end of the message in a turn.\n",
    "\n",
    "**<|start_header_id|>{role}<|end_header_id|>**: These tokens enclose the role for a particular message. The possible roles can be: system, user, assistant.\n",
    "\n",
    "**<|end_of_text|>:** This is equivalent to the EOS token. On generating this token, Llama 3 will cease to generate more tokens.\n",
    "\n",
    "A prompt can optionally contain a single system message, or multiple alternating user and assistant messages, but always ends with the last user message followed by the assistant header.\n",
    "\n",
    "## **Meta Llama 3**\n",
    "\n",
    "Code to produce this prompt format can be found [here](https://github.com/meta-llama/llama3/blob/main/llama/generation.py#L223).\n",
    "\n",
    "**Note**: Newlines (0x0A) are part of the prompt format, for clarity in the example, they have been represented as actual new lines.\n",
    "\n",
    "```\n",
    "<|begin_of_text|>{{ user_message }}\n",
    "```\n",
    "\n",
    "## **Meta Llama 3 Instruct**\n",
    "\n",
    "Code to generate this prompt format can be found [here](https://github.com/meta-llama/llama3/blob/main/llama/tokenizer.py#L203).\n",
    "\n",
    "**Notes**:\n",
    "\n",
    "- Newlines (0x0A) are part of the prompt format, for clarity in the examples, they have been represented as actual new lines.\n",
    "- The model expects the assistant header at the end of the prompt to start completing it.\n",
    "\n",
    "Decomposing an example instruct prompt with a system message:\n",
    "\n",
    "```\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are a helpful AI assistant for travel tips and recommendations<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "What can you help me with?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "```\n",
    "\n",
    "**<|begin_of_text|>**: Specifies the start of the prompt\n",
    "\n",
    "**<|start_header_id|>system<|end_header_id|>**: Specifies the role for the following message, i.e. “system”\n",
    "\n",
    "**You are a helpful AI assistant for travel tips and recommendations**: The system message\n",
    "\n",
    "**<|eot_id|>**: Specifies the end of the input message\n",
    "\n",
    "**<|start_header_id|>user<|end_header_id|>**: Specifies the role for the following message i.e. “user”\n",
    "\n",
    "**What can you help me with?**: The user message\n",
    "\n",
    "**<|start_header_id|>assistant<|end_header_id|>**: Ends with the assistant header, to prompt the model to start generation.\n",
    "\n",
    "Following this prompt, Llama 3 completes it by generating the {{assistant_message}}. It signals the end of the {{assistant_message}} by generating the **<|eot_id|>**.\n",
    "\n",
    "Example prompt with a single user message\n",
    "\n",
    "```\n",
    "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "What is France's capital?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "```\n",
    "\n",
    "System prompt and multiple turn conversation between the user and assistant\n",
    "\n",
    "```\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are a helpful AI assistant for travel tips and recommendations<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "What is France's capital?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "Bonjour! The capital of France is Paris!<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "What can I do there?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "Paris, the City of Light, offers a romantic getaway with must-see attractions like the Eiffel Tower and Louvre Museum, romantic experiences like river cruises and charming neighborhoods, and delicious food and drink options, with helpful tips for making the most of your trip.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Give me a detailed list of the attractions I should visit, and time it takes in each one, to plan my trip accordingly.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
