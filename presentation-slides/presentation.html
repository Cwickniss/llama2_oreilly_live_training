<!DOCTYPE html>
<html>
<head>
    <title>Presentation</title>
    <meta charset="utf-8">
    <style>
        @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
        @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
        @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

        body { font-family: 'Droid Serif'; }
        h1, h2, h3 {
            font-family: 'Yanone Kaffeesatz';
            font-weight: normal;
        }
        .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    </style>
</head>
<body>
<textarea id="source">
    class: center, middle
    
    # Getting Started with Llama3.1
    ## Lucas Soares
    ### 08-08-2024
    
    ---
    # Methodology Notes

    --
    1. Presentation Block

    --

    2. Notebook Demo

    --

    3. Quick Q&A + Summary

    --

    4. Optional Exercise During Q&A

    --

    5. Repeat

    ---
    
    # LLMs Predict the Next Word

    <img src="../notebooks/assets-resources/text-prediction-blnks.png" style="width: 100%"> 

    ---
    # LLMs Predict the Next Word

    <img src="../notebooks/assets-resources/chatgpt-text-prediction-1.png" style="width: 80%; margin-top: -10pt; margin-left: 80px; margin-top: -10pt; margin-left: 80px">

    ---

    # LLMs Predict the Next Word

    <img src="../notebooks/assets-resources/chatgpt-text-prediction-2.png" style="width: 80%; margin-top: -10pt; margin-left: 80px">
    ---

    # LLMs Predict the Next Word

    <img src="../notebooks/assets-resources/chatgpt-text-prediction-3.png" style="width: 80%; margin-top: -10pt; margin-left: 80px">
    ---

    # LLMs Predict the Next Word

    <img src="../notebooks/assets-resources/chatgpt-text-prediction-4.png" style="width: 80%; margin-top: -10pt; margin-left: 80px">
    ---

    # LLMs Predict the Next Word

    <img src="../notebooks/assets-resources/chatgpt-text-prediction-5.png" style="width: 80%; margin-top: -10pt; margin-left: 80px">
    ---

    # LLMs Predict the Next Word

    <img src="../notebooks/assets-resources/chatgpt-text-prediction-6.png" style="width: 80%; margin-top: -10pt; margin-left: 80px">
    
    ---
    # LLMs Predict the Next Word

    <img src="../notebooks/assets-resources/chatgpt-text-prediction-7.png" style="width: 80%; margin-top: -10pt; margin-left: 80px">

    ---

    <img src="../notebooks/assets-resources/llm_predicts_pancakes.png" style="width: 100%;margin-top: 100pt;">

    ---
    
    <img src="../notebooks/assets-resources/llm-prob-distributions-context.png" style="width:100%; margin-top: 40pt;">

    ---
    # Introduction to Llama3

    <img src="../notebooks/assets-resources/llama31-intro.png" width="100%">

    

    ---
    # Llama3.1 Release
    
    - LLM Released by Meta in July of 2024

    --

    - Open source with a Commercial license (just like Llama2 & Llama3)

    --

    - [Meta Llama3.1 Resources](https://ai.meta.com/llama/#resources)

    ---

    # Incredible Performance in 2 sizes

    --

    - Llama3.1 is OPEN SOURCE

    --
    
    - [Released in 3 sizes: 8B, 70B & 405B parameters.](https://ai.meta.com/blog/meta-llama-3-1/)

    --

    - Incredible evaluation performances for all  models.

    ---
    
    <img src="../notebooks/assets-resources/llama31-evals.png" style="width: 100%; margin-top: 40pt;">

       <p style="font-size: 14px; margin-top:50pt;">
        <a href='https://ai.meta.com/blog/meta-llama-3/#:~:text=a%20system-level%20approach%20to%20responsibility'>Meta AI Llama3.1 Release Blog Post</a>
      </p>

    ---

    # Llama 3.1 405B Rivals Closed Source Models

    <img src="../notebooks/assets-resources/llama31-evals-405b.png" style="width: 100%;"> 

      <p style="font-size: 14px; margin-top:50pt;">
        <a href='https://ai.meta.com/blog/meta-llama-3-1/'>Meta AI Llama3.1 Release Blog Post</a>
      </p>

    ---
    # Llama3.1 Technical Details

    - Data: Trained on over 15 trillion tokens of text data

    --
    
    - Context length: 128k tokens
    
    --
    
    - System level approach for responsible development

    <p style="font-size: 14px; margin-top:50pt;">
      <a href='https://ai.meta.com/blog/meta-llama-3/#:~:text=a%20system-level%20approach%20to%20responsibility'>Meta AI Llama3.1 Release Blog Post</a>
    </p>

    ---
    class: center,middle

    <h1>
    <span style="background-color: lightgreen">
      Notebook Demo - Introduction to Llama3.1
    </span>
    </h1>

    ---

    # Query Your Docs Locally with Llama3.1

    - Need for LLMs with access to context-relevant data.

    <img src="../notebooks/assets-resources/private-qa-llama2.png" width="50%" style="margin-left: 30pt;">

    ---
    # Query Your Docs Locall with Llama3.1

    - Privacy concern with closed source LLMs.

    <img src="../notebooks/assets-resources/llama2-rag-intro.png" width="50%" style="margin-left: 30pt;">
    
    ---
    # Query Your Docs Locall with Llama3.1
    
    - Solution? Llama3.1!

    <img src="../notebooks/assets-resources/llama2-rag-limitations.png" width="50%" style="margin-left: 30pt;">

    ---
    # RAG with Llama3.1
    - RAG - Retrieval Augmented Generation
    <img src="../notebooks/assets-resources/llama2-rag-what-why.png" width="80%">

    ---
    # RAG with Llama3.1

    - LLMs have a limited context length

    <img src="../notebooks/assets-resources/llama2-embeddings-content.png" width="80%">

    ---

    # Q&A RAG Tech Friction of Access

    - Framework for RAG Systems
    
    - Friction of Access
    
    <img src="../notebooks/assets-resources/tech-friction-access.png" width="80%">
    <p style="font-size: 14px; margin-top:50pt;">
        <a href='https://python.langchain.com/docs/use_cases/question_answering/'>Langchain Docs</a>
    </p>

    ---
    <img src="../notebooks/assets-resources/rag-llama3/rag-llama3.001.jpeg" style="width: 130%; margin-left:-100pt";>
    <p style="font-size: 14px; margin-top:50pt;">
        <a href='https://python.langchain.com/docs/use_cases/question_answering/'>Langchain Docs</a>
    </p>
    ---
    <img src="../notebooks/assets-resources/rag-llama3/rag-llama3.002.jpeg" style="width: 130%; margin-left:-100pt";>
    <p style="font-size: 14px; margin-top:50pt;">
        <a href='https://python.langchain.com/docs/use_cases/question_answering/'>Langchain Docs</a>
    </p>
    ---
    <img src="../notebooks/assets-resources/rag-llama3/rag-llama3.004.jpeg" style="width: 130%; margin-left:-100pt";>
    <p style="font-size: 14px; margin-top:50pt;">
        <a href='https://python.langchain.com/docs/use_cases/question_answering/'>Langchain Docs</a>
    </p>
    ---
    <img src="../notebooks/assets-resources/rag-llama3/rag-llama3.005.jpeg" style="width: 130%; margin-left:-100pt";>
    <p style="font-size: 14px; margin-top:50pt;">
        <a href='https://python.langchain.com/docs/use_cases/question_answering/'>Langchain Docs</a>
    </p>
    ---
    <img src="../notebooks/assets-resources/rag-llama3/rag-llama3.006.jpeg" style="width: 130%; margin-left:-100pt";>
    <p style="font-size: 14px; margin-top:50pt;">
        <a href='https://python.langchain.com/docs/use_cases/question_answering/'>Langchain Docs</a>
    </p>
    ---
    <img src="../notebooks/assets-resources/rag-llama3/rag-llama3.007.jpeg" style="width: 130%; margin-left:-100pt";>

    <p style="font-size: 14px; margin-top:50pt;">
      <a href='https://python.langchain.com/docs/use_cases/question_answering/'>Langchain Docs</a>
    </p>

    ---

    <img src="../notebooks/assets-resources/rag-llama3-pipeline/rag-llama3-pipeline.001.jpeg" style="width: 130%; margin-left:-100pt";>
    ---
    <img src="../notebooks/assets-resources/rag-llama3-pipeline/rag-llama3-pipeline.002.jpeg" style="width: 130%; margin-left:-100pt";>
    ---
    <img src="../notebooks/assets-resources/rag-llama3-pipeline/rag-llama3-pipeline.003.jpeg" style="width: 130%; margin-left:-100pt";>
    ---
    <img src="../notebooks/assets-resources/rag-llama3-pipeline/rag-llama3-pipeline.004.jpeg" style="width: 130%; margin-left:-100pt";>
    ---
    <img src="../notebooks/assets-resources/rag-llama3-pipeline/rag-llama3-pipeline.005.jpeg" style="width: 130%; margin-left:-100pt";>
    ---
        <img src="../notebooks/assets-resources/rag-llama3-pipeline/rag-llama3-pipeline.006.jpeg" style="width: 130%; margin-left:-100pt";>

    ---
    class: center, middle
    
    <h1>
    <span style="background-color: lightgreen">
      Notebook Demo - Local RAG with Llama 3.1
    </span>
    </h1>
    
    ---
    class: center, middle
    
    # Q&A / Break
    
    ---
    # Local Agents with Llama 3.1

    --
      
    <img src="../notebooks/assets-resources/agent-loop.png" width="1500">

    <p class="footnote">
        <a href='https://blog.langchain.dev/openais-bet-on-a-cognitive-architecture/'> Explanation of the agent loop in cognitive architectures. </a>
    </p>

    ---

    # Practical Use Case: Customer Support Agent

    --
    
    - **Scenario**: An LLM-powered customer support agent.

    --
    
    - **User Input**: Customer asks about order status.

    --
    
    - **LLM Decision**: Determines if it can provide the status directly or if it needs to fetch data from the database.

    --
    
    - **Action Taken**: If data fetch is needed, the agent queries the database and updates the user with the order status.

    <p class="footnote">
        <a href='https://langchain-ai.github.io/langgraph/concepts/high_level/#deployment'> Practical use case of LLM agents in customer support. </a>
    </p>

    ---
    class: center, middle

      <h1>
      <span style="background-color: lightgreen">
        Notebook Demo - Tool Calling and local agents with Llama 3.1
      </span>
      </h1>
    ---
    class: center, middle

    # Q&A / Break

    ---
    class: center, middle

    # Fine Tunning Llama3.1

    ---
    <img src="../notebooks/assets-resources/finetuning-llama3/finetuning-llama3.001.jpeg" style="width: 130%; margin-left:-100pt";>

    <p style="font-size: 14px; margin-top: 50pt;">
        <a href='https://arxiv.org/pdf/2307.09288'>LLama2 Paper</a>
      </p>
    ---
    <img src="../notebooks/assets-resources/finetuning-llama3/finetuning-llama3.002.jpeg" style="width: 130%; margin-left:-100pt";>

    <p style="font-size: 14px; margin-top: 50pt;">
        <a href='https://www.youtube.com/watch?v=g68qlo9Izf0&t=2935s'>Efficient Fine-Tuning for Llama-v2-7b on a Single GPU</a>
      </p>
    ---
    <img src="../notebooks/assets-resources/finetuning-llama3/finetuning-llama3.003.jpeg" style="width: 130%; margin-left:-100pt";>

    <p style="font-size: 14px; margin-top: 50pt;">
        <a href='https://www.youtube.com/watch?v=g68qlo9Izf0&t=2935s'>Efficient Fine-Tuning for Llama-v2-7b on a Single GPU</a>
      </p>
    ---
    <img src="../notebooks/assets-resources/finetuning-llama3/finetuning-llama3.004.jpeg" style="width: 130%; margin-left:-100pt";>

    <p style="font-size: 14px; margin-top: 50pt;">
      <a href='https://www.youtube.com/watch?v=g68qlo9Izf0&t=2935s'>Efficient Fine-Tuning for Llama-v2-7b on a Single GPU</a>
    </p>
    ---
    <img src="../notebooks/assets-resources/finetuning-llama3/finetuning-llama3.005.jpeg" style="width: 130%; margin-left:-100pt";>
    ---
    <img src="../notebooks/assets-resources/finetuning-llama3/finetuning-llama3.006.jpeg" style="width: 130%; margin-left:-100pt";>

    <p style="font-size: 14px; margin-top: 50pt;">
      <a href='https://arxiv.org/pdf/2106.09685'>Lora Paper</a>
    </p>
    ---
    class: center, middle

      <h1>
      <span style="background-color: lightgreen">
        Notebook Demo - Fine-Tuning Llama3.1 - Walkthrough
      </span>
      </h1>



</textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js">
</script>
<script>
var slideshow = remark.create();
</script>
</body>
</html>