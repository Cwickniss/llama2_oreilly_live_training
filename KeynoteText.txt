Slide 1:Getting Started with Llama2Lucas Soares
05-02-2023Slide 2:IntroHi!IntroSlide 3:Interactive Methodology for this Live-TrainingSlide 4:Large Language ModelsA definitionLarge Language ModelsSlide 5:Large Language ModelsAs Probability DistributionsAt their core, LLMs can be seen as distributions over words.Large Language ModelsSlide 6:Large Language ModelsAs Probability DistributionsAt their core, LLMs can be seen as distributions over words.Use statistical models to capture patterns in text data.Large Language ModelsSlide 7:Large Language ModelsAs Probability DistributionsAt their core, LLMs can be seen as distributions over words.Use statistical models to capture patterns in text data.They calculate the likelihood of each word occurring given the context.Probability Distribution over the Next Word“I love eating….” ? ?pie pastafruit pancakesbread Large Language ModelsSlide 8:How LLMs workTransformers ArchitectureTraditional sequential models struggle with context (Vaswani et al 2017)Transformers use attention mechanisms to capture global dependencies, enabling contextual understanding. (Vaswani et al 2017)The attention mechanism allows Transformers to focus on different parts of input simultaneously. (Vaswani et al 2017)Transformers can understand and predict based on long-range dependencies. (Vaswani et al 2017)How LLMs workSlide 9:Introduction to Llama2Introduction to Llama2Prompt Engineering with Llama2Query Your docs LocallyFine Tune Your Llama2 Model1324Table of ContentsSlide 10:Introduction to Llama21LLM Released by Meta in July of 2023Open source with a Comercial licensehttps://ai.meta.com/llama/#resourcesWhat, why & how Llama2?Slide 11:Introduction to Llama2What, why & how Llama2?Llama2 is OPEN SOURCEBenefits of Large Language ModelsSlide 12:Comes in 3 different sizes: 
7b, 13B & 70B parametersIntroduction to Llama2What, why & how Llama2?Llama2 is OPEN SOURCEBenefits of Large Language ModelsSlide 13:Comes in 3 different sizes: 
7b, 13B & 70B parametersIntroduction to Llama2What, why & how Llama2?Llama2 is OPEN SOURCEData: Trained on 2 trillion 
tokens of text dataBenefits of Large Language ModelsSlide 14:Comes in 3 different sizes: 
7b, 13B & 70B parametersContext Window: 4096 tokensIntroduction to Llama2What, why & how Llama2?Llama2 is OPEN SOURCEData: Trained on 2 trillion 
tokens of text dataBenefits of Large Language ModelsSlide 15:Comes in 3 different sizes: 
7b, 13B & 70B parametersContext Window: 4096 tokensIntroduction to Llama2What, why & how Llama2?Llama2 is OPEN SOURCEData: Trained on 2 trillion 
tokens of text dataSafety & HelpfulnessBenefits of Large Language ModelsSlide 16:Comes in 3 different sizes: 
7b, 13B & 70B parametersContext Window: 4096 tokensIntroduction to Llama2What, why & how Llama2?Llama2 is OPEN SOURCEData: Trained on 2 trillion 
tokens of text dataSafety & HelpfulnessBenefits of Large Language ModelsSlide 17:Introduction to Llama2What, why & how Llama2?https://arxiv.org/pdf/2307.09288.pdfBenefits of Large Language ModelsSlide 18:Introduction to Llama2What, why & how Llama2?https://arxiv.org/pdf/2307.09288.pdfNotebook demoBenefits of Large Language ModelsSlide 19:Q&A / BreakSlide 20:Prompt Engineering GuideWhat is prompt engineering?3Prompt Engineering GuideSlide 21:Prompt Engineering GuideWhat is prompt engineering?Prompt engineering: discipline for engineering prompts3Prompt Engineering GuideSlide 22:Prompt Engineering GuideWhat is prompt engineering?Prompt engineering: discipline for engineering promptsThe basic goal of prompt engineering is designing good prompts.3Prompt Engineering GuideSlide 23:Prompt Engineering GuideWhat is prompt engineering?Prompt engineering: Discipline for engineering prompts3It’s about having a process for developing good prompts that yield high performance across tasks.The basic goal of prompt engineering is designing good prompts.Prompt Engineering GuideSlide 24:Prompt Engineering GuideWhat is prompt engineering?Prompt engineering: Discipline for engineering prompts3It’s about having a process for developing good prompts that yield high performance across tasks.The basic goal of prompt engineering is designing good prompts.Prompt Engineering GuideSlide 25:Prompt Engineering GuideOpenAI’s Guide for Building Good PromptsPrompt Engineering GuideSlide 26:Prompt Engineering GuideOpenAI’s Guide for Building Good PromptsStrategy 1: Write clear instructionsOpenAI docsPrompt Engineering GuideSlide 27:Prompt Engineering GuideOpenAI’s Guide for Building Good PromptsStrategy 1: Write clear instructionsBad: Who’s president?
Better: Who was the president of Mexico in 2021? OpenAI docsPrompt Engineering GuideSlide 28:Prompt Engineering GuideOpenAI’s Guide for Building Good PromptsStrategy 1: Write clear instructionsStrategy 2: Provide reference textOpenAI docsPrompt Engineering GuideSlide 29:Prompt Engineering GuideOpenAI’s Guide for Building Good PromptsStrategy 1: Write clear instructionsSYSTEM
Use the provided articles delimited by triple quotes to answer questions. If the answer cannot be found in the articles, write "I could not find an answer."
USER
<insert articles, each delimited by triple quotes>
Question: <insert question here>Strategy 2: Provide reference textPrompt Engineering GuideSlide 30:Prompt Engineering GuideOpenAI’s Guide for Building Good PromptsStrategy 1: Write clear instructionsStrategy 3: Break tasks into subtasksStrategy 2: Provide reference textOpenAI docsPrompt Engineering GuideSlide 31:Prompt Engineering GuideOpenAI’s Guide for Building Good PromptsStrategy 1: Write clear instructionsStrategy 3: Break tasks into subtasksStrategy 2: Provide reference textPrompt Engineering GuideSlide 32:Prompt Engineering GuideOpenAI’s Guide for Building Good PromptsStrategy 1: Write clear instructionsStrategy 3: Break tasks into subtasksStrategy 4: Give the model time to thinkStrategy 2: Provide reference textOpenAI docsPrompt Engineering GuideSlide 33:Prompt Engineering GuideOpenAI’s Guide for Building Good PromptsStrategy 1: Write clear instructionsStrategy 3: Break tasks into subtasksStrategy 4: Give the model time to thinkStrategy 2: Provide reference textSYSTEM
Follow these steps to answer the user queries.

Step 1 - First work out your own solution to the problem. Don't rely on the student's solution since it may be incorrect. Enclose all your work for this step within triple quotes (""").

Step 2 - Compare your solution to the student's solution and evaluate if the student's solution is correct or not. Enclose all your work for this step within triple quotes (""").

Step 3 - If the student made a mistake, determine what hint you could give the student without giving away the answer. Enclose all your work for this step within triple quotes (""").

Step 4 - If the student made a mistake, provide the hint from the previous step to the student (outside of triple quotes). Instead of writing "Step 4 - ..." write "Hint:".
USER
Problem Statement: <insert problem statement>

Student Solution: <insert student solution>
Prompt Engineering GuideSlide 34:Prompt Engineering GuideOpenAI’s Guide for Building Good PromptsStrategy 1: Write clear instructionsStrategy 3: Break tasks into subtasksStrategy 4: Give the model time to thinkStrategy 5: Use external toolsStrategy 2: Provide reference textOpenAI docsPrompt Engineering GuideSlide 35:Prompt Engineering GuideOpenAI’s Guide for Building Good PromptsStrategy 1: Write clear instructionsStrategy 3: Break tasks into subtasksStrategy 4: Give the model time to thinkStrategy 5: Use external toolsStrategy 2: Provide reference textSYSTEM
You can write and execute Python code by enclosing it in triple backticks, e.g. ```code goes here```. Use this to perform calculations.
USER
Find all real-valued roots of the following polynomial: 3*x**5 - 5*x**4 - 3*x**3 - 7*x - 10.
Prompt Engineering GuideSlide 36:Prompt Engineering GuideOpenAI’s Guide for Building Good PromptsStrategy 1: Write clear instructionsStrategy 3: Break tasks into subtasksStrategy 4: Give the model time to thinkStrategy 5: Use external toolsStrategy 6: Test changes systematicallyStrategy 2: Provide reference textOpenAI docsPrompt Engineering GuideSlide 37:Prompt Engineering GuideOpenAI’s Guide for Building Good PromptsStrategy 1: Write clear instructionsStrategy 3: Break tasks into subtasksStrategy 4: Give the model time to thinkStrategy 5: Use external toolsStrategy 6: Test changes systematicallyStrategy 2: Provide reference textEvaluation procedures are useful for optimizing system designs. Good evals are:
Representative of real-world usage (or at least diverse)
Contain many test cases for greater statistical power (see table below for guidelines)
Easy to automate or repeatPrompt Engineering GuideSlide 38:Prompt Engineering GuideOpenAI’s Guide for Building Good PromptsStrategy 1: Write clear instructionsStrategy 3: Break tasks into subtasksStrategy 4: Give the model time to thinkStrategy 5: Use external toolsStrategy 6: Test changes systematicallyStrategy 2: Provide reference textEvaluation procedures are useful for optimizing system designs. Good evals are:
Representative of real-world usage (or at least diverse)
Contain many test cases for greater statistical power (see table below for guidelines)
Easy to automate or repeatNotebook Demo - Prompt Engineering with Llama2Prompt Engineering GuideSlide 39:Q&A / BreakSlide 40:4Query Your Docs Locally with Llama2Private Q&As with docs using Llama2Need for LLMs with access to context-relevant dataA Framework for Building Good PromptsSlide 41:4Query Your Docs Locally with Llama2Private Q&As with docs using Llama2Privacy concern with 
closed source LLMs Need for LLMs with access to context-relevant dataA Framework for Building Good PromptsSlide 42:4Query Your Docs Locally with Llama2Private Q&As with docs using Llama2Solution?Local LLMs! (Aka Llama2!)Privacy concern with 
closed source LLMs Need for LLMs with access to context-relevant dataA Framework for Building Good PromptsSlide 43:LLMQuery Your Docs Locally with Llama2What & Why RAGs?RAG - Retrieval Augmented GenerationQuery Your Docs Locally with Llama2Slide 44:Query Your Docs Locally with Llama2What & Why RAGs?RAG - Retrieval Augmented Generationhttps://python.langchain.com/docs/use_cases/question_answering/Query Your Docs Locally with Llama2Slide 45:Query Your Docs Locally with Llama2What & Why RAGs?RAG - Retrieval Augmented Generationhttps://python.langchain.com/docs/use_cases/question_answering/LLMQuery Your Docs Locally with Llama2Slide 46:LLMs have a limited context lengthQuery Your Docs Locally with Llama2Private Q&As with docs using Llama2RAG - Retrieval Augmented GenerationLangchain for LLM App Development Slide 47:LLMs have a limited context lengthQuery Your Docs Locally with Llama2Private Q&As with docs using Llama2RAG - Retrieval Augmented Generationchunk chunk chunk chunk Langchain for LLM App Development Slide 48:LLMs have a limited context lengthQuery Your Docs Locally with Llama2Private Q&As with docs using Llama2RAG - Retrieval Augmented Generationchunk chunk chunk chunk Embeddings Embeddings Embeddings Embeddings Langchain for LLM App Development Slide 49:LLMs have a limited context length[0.1,0.0456,….]Query Your Docs Locally with Llama2Private Q&As with docs using Llama2RAG - Retrieval Augmented Generationchunk chunk chunk chunk Embeddings Embeddings Embeddings Embeddings [0.1,0.0456,….][0.1,0.0456,….][0.1,0.0456,….]Langchain for LLM App Development Slide 50:Embeddings [0.1,0.0456,….]Embeddings [0.004,0.06,….]My dog likes foodMy cat hates waking upEmbeddings [0.7,0.0135,….]Query Your Docs Locally with Llama2I will learn about llama2Private Q&As with docs using Llama2LLMs have a limited context lengthEmbeddings: capture content and meaning RAG - Retrieval Augmented GenerationLangchain for LLM App Development Slide 51:Query Your Docs Locally with Llama2Private Q&As with docs using Llama2LLMs have a limited context lengthEmbeddings: capture content and meaning RAG - Retrieval Augmented GenerationSimilarNot similarSimilarEmbeddings [0.1,0.0456,….]Embeddings [0.004,0.06,….]My dog likes foodMy cat hates waking upI will learn about llama2Embeddings [0.7,0.0135,….]Langchain for LLM App Development Slide 52:Query Your Docs Locally with Llama2Private Q&As with docs using Llama2LLMs have a limited context lengthEmbeddings: capture content and meaning RAG - Retrieval Augmented GenerationQueryVector DatabaseLangchain for LLM App Development Slide 53:Query Your Docs Locally with Llama2Private Q&As with docs using Llama2LLMs have a limited context lengthEmbeddings: capture content and meaning RAG - Retrieval Augmented GenerationQueryVector DatabaseNotebook demoLangchain for LLM App Development Slide 54:Q&A / BreakSlide 55:Q&A Tech Friction of AccessQuery Your Docs Locally with Llama2Framework for RAG SystemsFriction of AccessLangchain for LLM App Development Slide 56:Q&A Tech Friction of AccessQuery Your Docs Locally with Llama2Framework for RAG SystemsFriction of AccessOpenAI,ChatPDFLangchain for LLM App Development Slide 57:Q&A Tech Friction of AccessQuery Your Docs Locally with Llama2Framework for RAG SystemsFriction of AccessOpenAI,ChatPDF, Hugging Face, h20GPTLangchain for LLM App Development Slide 58:Q&A Tech Friction of AccessQuery Your Docs Locally with Llama2Framework for RAG SystemsFriction of AccessOpenAI,ChatPDF, Hugging Face, h20GPT, PrivateGPT, LocalGPTLangchain for LLM App Development Slide 59:Q&A Tech Friction of AccessQuery Your Docs Locally with Llama2Framework for RAG SystemsFriction of AccessOpenAI,ChatPDF, Hugging Face, h20GPT, PrivateGPT, LocalGPT, Langchain, Llama-index Langchain for LLM App Development Slide 60:Q&A Tech Friction of AccessQuery Your Docs Locally with Llama2Framework for RAG SystemsFriction of AccessOpenAI,ChatPDF, Hugging Face, h20GPT, PrivateGPT, LocalGPT, Langchain, Llama-index Langchain for LLM App Development Slide 61:Query Your Docs Locally with Llama2Framework for RAG Systemshttps://python.langchain.com/docs/use_cases/question_answering/Langchain for LLM App Development Slide 62:Query Your Docs Locally with Llama2Framework for RAG Systemshttps://python.langchain.com/docs/use_cases/question_answering/Langchain for LLM App Development Slide 63:Query Your Docs Locally with Llama2Framework for RAG Systemshttps://python.langchain.com/docs/use_cases/question_answering/Langchain for LLM App Development Slide 64:Query Your Docs Locally with Llama2Framework for RAG Systemshttps://python.langchain.com/docs/use_cases/question_answering/Langchain for LLM App Development Slide 65:Query Your Docs Locally with Llama2Framework for RAG Systemshttps://python.langchain.com/docs/use_cases/question_answering/Langchain for LLM App Development Slide 66:Query Your Docs Locally with Llama2Framework for RAG Systemshttps://python.langchain.com/docs/use_cases/question_answering/Langchain for LLM App Development Slide 67:Load DocumentChunk, Split, ProcessEmbedQuery Your Docs Locally with Llama2Framework for RAG SystemsVectorise, indexQuery IndexProcess responseLangchain for LLM App Development Slide 68:Load DocumentChunk, Split, ProcessEmbedQuery Your Docs Locally with Llama2Framework for RAG SystemsVectorise, indexQuery IndexProcess responseNotebook demoLangchain for LLM App Development Slide 69:Q&A / BreakSlide 70:What is Fine Tuning?Fine Tuning Llama2What, why & how.https://arxiv.org/pdf/2307.09288.pdfLangchain for LLM App Development Slide 71:What is Fine Tuning?Fine Tuning Llama2What, why & how.Why Fine Tune?https://www.youtube.com/watch?v=g68qlo9Izf0&t=2935sLangchain for LLM App Development Slide 72:What is Fine Tuning?Memory cost of LLMs: parameters, gradients, optimiser statesFine Tuning Llama2What, why & how.Why Fine Tune?Langchain for LLM App Development Slide 73:Problem - Loading ParamsFine Tuning Llama2What, why & how.Solution - Half Precisionhttps://www.youtube.com/watch?v=g68qlo9Izf0&t=2935sLangchain for LLM App Development Slide 74:Problem - Loading ParamsProblem - Loading GradientsFine Tuning Llama2What, why & how.Solution - Half PrecisionSolution - QuantizationLangchain for LLM App Development Slide 75:Problem - Loading ParamsProblem - Loading GradientsProblem - Loading Optimizer StatesFine Tuning Llama2What, why & how.Solution - Half PrecisionSolution - QuantizationSolution - LoRA, QLoraLangchain for LLM App Development Slide 76:Problem - Loading ParamsProblem - Loading GradientsProblem - Loading Optimizer StatesFine Tuning Llama2What, why & how.Solution - Half PrecisionSolution - QuantizationSolution - LoRA, QLoraLangchain for LLM App Development Slide 77:Problem - Loading ParamsProblem - Loading GradientsProblem - Loading Optimizer StatesFine Tuning Llama2What, why & how.Solution - Half PrecisionSolution - QuantizationSolution - LoRA, QLoraNotebook demoLangchain for LLM App Development 